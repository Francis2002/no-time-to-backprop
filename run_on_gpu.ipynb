{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7807525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%rm -rf no-time-to-backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fddc64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n",
      "Tue Dec 23 19:11:15 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c641917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'no-time-to-backprop'...\n",
      "remote: Enumerating objects: 332, done.\u001b[K\n",
      "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
      "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
      "remote: Total 332 (delta 122), reused 123 (delta 58), pack-reused 138 (from 1)\u001b[K\n",
      "Receiving objects: 100% (332/332), 98.11 MiB | 15.24 MiB/s, done.\n",
      "Resolving deltas: 100% (191/191), done.\n",
      "/content/no-time-to-backprop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.80\"\n",
    "\n",
    "!git clone https://github.com/Francis2002/no-time-to-backprop.git\n",
    "%cd no-time-to-backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2939153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n",
      "constraints.txt\t\t\t requirements-linux-cuda.txt  run_all_toy.sh\n",
      "hpt.py\t\t\t\t requirements-macos-cpu.txt   run_on_gpu.ipynb\n",
      "plotting_scripts\t\t requirements.mac.txt\t      run_toy_task.py\n",
      "requirements-base.txt\t\t requirements.txt\t      test_rec.py\n",
      "requirements.from_linux_env.txt  run_all_benchmarks.sh\t      tgap\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e5e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==2.3.1 (from -r requirements.txt (line 2))\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: alembic==1.17.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: attrs==25.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (25.4.0)\n",
      "Collecting chex==0.1.91 (from -r requirements.txt (line 5))\n",
      "  Downloading chex-0.1.91-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting colorlog==6.10.1 (from -r requirements.txt (line 6))\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy==1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: dm-tree==0.1.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.1.9)\n",
      "Collecting flax==0.12.1 (from -r requirements.txt (line 10))\n",
      "  Downloading flax-0.12.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fonttools==4.61.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.61.1)\n",
      "Requirement already satisfied: joblib==1.5.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.5.3)\n",
      "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.4.9)\n",
      "Requirement already satisfied: Mako==1.3.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.3.10)\n",
      "Requirement already satisfied: markdown-it-py==4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (3.0.3)\n",
      "Collecting matplotlib==3.10.8 (from -r requirements.txt (line 19))\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: ml_dtypes==0.5.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (0.5.4)\n",
      "Requirement already satisfied: msgpack==1.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (1.1.2)\n",
      "Collecting numpy==2.3.5 (from -r requirements.txt (line 23))\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt_einsum==3.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (3.4.0)\n",
      "Requirement already satisfied: optax==0.2.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (0.2.6)\n",
      "Collecting optuna==4.6.0 (from -r requirements.txt (line 26))\n",
      "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (25.0)\n",
      "Collecting pandas==2.3.3 (from -r requirements.txt (line 28))\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow==12.0.0 (from -r requirements.txt (line 29))\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: Pygments==2.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (2.19.2)\n",
      "Requirement already satisfied: pyparsing==3.2.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (6.0.3)\n",
      "Collecting rich==14.2.0 (from -r requirements.txt (line 35))\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting scikit-learn==1.8.0 (from -r requirements.txt (line 36))\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy==1.16.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 37)) (1.16.3)\n",
      "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (1.17.0)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.45 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 39)) (2.0.45)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 40)) (3.6.0)\n",
      "Collecting tomli==2.3.0 (from -r requirements.txt (line 41))\n",
      "  Downloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting toolz==1.1.0 (from -r requirements.txt (line 42))\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (4.15.0)\n",
      "Requirement already satisfied: tzdata==2025.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 45)) (2025.3)\n",
      "Requirement already satisfied: wrapt==2.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 46)) (2.0.1)\n",
      "Collecting jax==0.8.1 (from jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jaxlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from chex==0.1.91->-r requirements.txt (line 5)) (0.7.2)\n",
      "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax==0.12.1->-r requirements.txt (line 10)) (0.11.31)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax==0.12.1->-r requirements.txt (line 10)) (0.1.80)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.1->-r requirements.txt (line 10)) (0.1.10)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy==2.0.45->-r requirements.txt (line 39)) (3.3.0)\n",
      "Collecting jaxlib>=0.7.0 (from chex==0.1.91->-r requirements.txt (line 5))\n",
      "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting jax-cuda12-plugin<=0.8.1,>=0.8.1 (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading jax_cuda12_plugin-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting jax-cuda12-pjrt==0.8.1 (from jax-cuda12-plugin<=0.8.1,>=0.8.1->jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading jax_cuda12_pjrt-0.8.1-py3-none-manylinux_2_27_x86_64.whl.metadata (579 bytes)\n",
      "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.80)\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.8 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12>=12.1.55 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12>=3.2.5 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (3.3.20)\n",
      "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (1.13.0)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (1.6.0)\n",
      "Collecting aiofiles (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (4.14.0)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (3.20.2)\n",
      "Collecting psutil (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Collecting fsspec (from etils[epath,epy]->orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (6.5.2)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (3.23.0)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chex-0.1.91-py3-none-any.whl (100 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading flax-0.12.1-py3-none-any.whl (488 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.2/488.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.8.1-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax_cuda12_plugin-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading jax_cuda12_pjrt-0.8.1-py3-none-manylinux_2_27_x86_64.whl (150.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.5/150.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jax-cuda12-pjrt, toolz, tomli, psutil, protobuf, pillow, nvidia-cuda-nvcc-cu12, numpy, jax-cuda12-plugin, fsspec, colorlog, aiofiles, absl-py, rich, pandas, scikit-learn, optuna, matplotlib, jaxlib, jax, chex, flax\n",
      "  Attempting uninstall: jax-cuda12-pjrt\n",
      "    Found existing installation: jax-cuda12-pjrt 0.7.2\n",
      "    Uninstalling jax-cuda12-pjrt-0.7.2:\n",
      "      Successfully uninstalled jax-cuda12-pjrt-0.7.2\n",
      "  Attempting uninstall: toolz\n",
      "    Found existing installation: toolz 0.12.1\n",
      "    Uninstalling toolz-0.12.1:\n",
      "      Successfully uninstalled toolz-0.12.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.5\n",
      "    Uninstalling psutil-5.9.5:\n",
      "      Successfully uninstalled psutil-5.9.5\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.3.0\n",
      "    Uninstalling pillow-11.3.0:\n",
      "      Successfully uninstalled pillow-11.3.0\n",
      "  Attempting uninstall: nvidia-cuda-nvcc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: jax-cuda12-plugin\n",
      "    Found existing installation: jax-cuda12-plugin 0.7.2\n",
      "    Uninstalling jax-cuda12-plugin-0.7.2:\n",
      "      Successfully uninstalled jax-cuda12-plugin-0.7.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 24.1.0\n",
      "    Uninstalling aiofiles-24.1.0:\n",
      "      Successfully uninstalled aiofiles-24.1.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.4.0\n",
      "    Uninstalling absl-py-1.4.0:\n",
      "      Successfully uninstalled absl-py-1.4.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.9.4\n",
      "    Uninstalling rich-13.9.4:\n",
      "      Successfully uninstalled rich-13.9.4\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.0\n",
      "    Uninstalling matplotlib-3.10.0:\n",
      "      Successfully uninstalled matplotlib-3.10.0\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.7.2\n",
      "    Uninstalling jaxlib-0.7.2:\n",
      "      Successfully uninstalled jaxlib-0.7.2\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.7.2\n",
      "    Uninstalling jax-0.7.2:\n",
      "      Successfully uninstalled jax-0.7.2\n",
      "  Attempting uninstall: chex\n",
      "    Found existing installation: chex 0.1.90\n",
      "    Uninstalling chex-0.1.90:\n",
      "      Successfully uninstalled chex-0.1.90\n",
      "  Attempting uninstall: flax\n",
      "    Found existing installation: flax 0.10.7\n",
      "    Uninstalling flax-0.10.7:\n",
      "      Successfully uninstalled flax-0.10.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
      "bigframes 2.31.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.2 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.2 which is incompatible.\n",
      "gradio 5.50.0 requires aiofiles<25.0,>=22.0, but you have aiofiles 25.1.0 which is incompatible.\n",
      "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.2 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.3.1 aiofiles-25.1.0 chex-0.1.91 colorlog-6.10.1 flax-0.12.1 fsspec-2025.12.0 jax-0.8.1 jax-cuda12-pjrt-0.8.1 jax-cuda12-plugin-0.8.1 jaxlib-0.8.1 matplotlib-3.10.8 numpy-2.3.5 nvidia-cuda-nvcc-cu12-12.9.86 optuna-4.6.0 pandas-2.3.3 pillow-12.0.0 protobuf-6.33.2 psutil-7.1.3 rich-14.2.0 scikit-learn-1.8.0 tomli-2.3.0 toolz-1.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "a6dd68daa30a48a08ccaa47d7bf06499",
       "pip_warning": {
        "packages": [
         "PIL",
         "google",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "psutil"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install -r requirements-linux-cuda.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bb9164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax: 0.8.1\n",
      "jaxlib: 0.8.1\n",
      "executable: /usr/bin/python3\n",
      "devices: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jaxlib\n",
    "import sys\n",
    "\n",
    "print(f\"jax: {jax.__version__}\")\n",
    "print(f\"jaxlib: {jaxlib.__version__}\")\n",
    "print(f\"executable: {sys.executable}\")\n",
    "print(f\"devices: {jax.devices()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5b4113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Results will be stored in /content/no-time-to-backprop/results_for_rotational_vs_none/mooc_ONLINE\n",
      "[*] d_model set to 64\n",
      "Running iteration: 0\n",
      "[*] Output file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists. Using existing file.\n",
      "object address  : 0x7bd2cbad2f20\n",
      "object refcount : 3\n",
      "object type     : 0xa2a4e0\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 run_toy_task.py -m ONLINE -a ZUC --dataset mooc --task link_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156846a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*] Results will be stored in /content/no-time-to-backprop/results_for_benchmarks/mooc_ONLINE\n",
      "[*] d_model set to 32\n",
      "\u001b[32m[I 2025-12-23 19:12:45,913]\u001b[0m A new study created in memory with name: no-name-a4e93f13-99bf-4d22-b241-d154c6f06ddb\u001b[0m\n",
      "\n",
      "[*] ----------------------------- Iteration: 0 -----------------------------\n",
      "\n",
      "[*] Trial: <optuna.trial._trial.Trial object at 0x7801fbc07920>\n",
      "[*] HPT: {'memory': 5, 'seed': 43, 'num_layers': 4, 'state_size': 50, 'd_model_factor': 1.0, 'dropout': 0.07326237754544744, 'pos_weight': 1.8862423347191157, 'batch_size': 128, 'n_accumulation_steps': 11, 'learning_rate': 0.00010255775205731647, 'rec_learning_factor': 0.5, 'beta1': 0.8835860676854593, 'beta2': 0.983366232402884, 'weight_decay': 0.035834535831831535}\n",
      "[*] Npz file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists with matching meta. Using existing file.\n",
      "W1223 19:12:46.170364     684 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1223 19:12:46.172410     669 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "\n",
      "[*] -------------------- Dataset Statistics --------------------\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz\n",
      "[*] Number of nodes: 7047\n",
      "[*] Total number of edges used: 411648\n",
      "[*] Val_ratio: 0.2 | Test_ratio: 0.2\n",
      "[*] Number of features: 6\n",
      "[*] -----------------------------------------------------------\n",
      "\n",
      "[*] Trainable Parameters: 103601\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- decoder\n",
      "|  |  |  |- bias  shape=(1,)\n",
      "|  |  |  |- kernel  shape=(50, 1)\n",
      "|  |  |- encoder\n",
      "|  |     |- encoder\n",
      "|  |     |  |- bias  shape=(50,)\n",
      "|  |     |  |- kernel  shape=(6, 50)\n",
      "|  |     |- layers_0\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(100, 50)\n",
      "|  |     |     |- B_re  shape=(100, 50)\n",
      "|  |     |     |- C_im  shape=(50, 100)\n",
      "|  |     |     |- C_re  shape=(50, 100)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(100,)\n",
      "|  |     |     |- nu  shape=(200,)\n",
      "|  |     |     |- phi  shape=(50,)\n",
      "|  |     |     |- theta  shape=(200,)\n",
      "|  |     |- layers_1\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(100, 50)\n",
      "|  |     |     |- B_re  shape=(100, 50)\n",
      "|  |     |     |- C_im  shape=(50, 100)\n",
      "|  |     |     |- C_re  shape=(50, 100)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(100,)\n",
      "|  |     |     |- nu  shape=(200,)\n",
      "|  |     |     |- phi  shape=(50,)\n",
      "|  |     |     |- theta  shape=(200,)\n",
      "|  |     |- layers_2\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(100, 50)\n",
      "|  |     |     |- B_re  shape=(100, 50)\n",
      "|  |     |     |- C_im  shape=(50, 100)\n",
      "|  |     |     |- C_re  shape=(50, 100)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(100,)\n",
      "|  |     |     |- nu  shape=(200,)\n",
      "|  |     |     |- phi  shape=(50,)\n",
      "|  |     |     |- theta  shape=(200,)\n",
      "|  |     |- layers_3\n",
      "|  |        |- norm\n",
      "|  |        |  |- bias  shape=(50,)\n",
      "|  |        |  |- scale  shape=(50,)\n",
      "|  |        |- out1\n",
      "|  |        |  |- bias  shape=(50,)\n",
      "|  |        |  |- kernel  shape=(50, 50)\n",
      "|  |        |- out2\n",
      "|  |        |  |- bias  shape=(50,)\n",
      "|  |        |  |- kernel  shape=(50, 50)\n",
      "|  |        |- seq\n",
      "|  |           |- B_im  shape=(100, 50)\n",
      "|  |           |- B_re  shape=(100, 50)\n",
      "|  |           |- C_im  shape=(50, 100)\n",
      "|  |           |- C_re  shape=(50, 100)\n",
      "|  |           |- D  shape=(50,)\n",
      "|  |           |- gamma_log  shape=(100,)\n",
      "|  |           |- nu  shape=(200,)\n",
      "|  |           |- phi  shape=(50,)\n",
      "|  |           |- theta  shape=(200,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 100)\n",
      "|        |- layers_1\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 100)\n",
      "|        |- layers_2\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 100)\n",
      "|        |- layers_3\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(128, 100)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py:5518: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "[*] Training Loss: 0.9683310389518738\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1587434560060501\n",
      "mean sig(logit) neg = 0.19124799966812134\n",
      "mean logit pos = -2.204996347427368\n",
      "mean logit neg = -1.9072420597076416\n",
      "[*] Val Loss: 0.28720369935035706\n",
      "[*] Val roc_auc: 0.43475101291089613\n",
      "\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1671738177537918\n",
      "mean sig(logit) neg = 0.19278556108474731\n",
      "mean logit pos = -2.1175360679626465\n",
      "mean logit neg = -1.9194387197494507\n",
      "[*] Test Loss: 0.29913127422332764\n",
      "[*] Test roc_auc: 0.4563852551774107\n",
      "\n",
      "[*] Best val loss: 0.28720369935035706 at epoch 1\n",
      "[*] Best Val ROC AUC: 0.43475101291089613 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.4563852551774107 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 2...\n",
      "[*] Training Loss: 0.2352907657623291\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.012641762383282185\n",
      "mean sig(logit) neg = 0.01589694805443287\n",
      "mean logit pos = -5.06027889251709\n",
      "mean logit neg = -4.80551290512085\n",
      "[*] Val Loss: 0.09997007995843887\n",
      "[*] Val roc_auc: 0.4381816036513252\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.01408498827368021\n",
      "mean sig(logit) neg = 0.0172350462526083\n",
      "mean logit pos = -5.0014495849609375\n",
      "mean logit neg = -4.806698799133301\n",
      "[*] Test Loss: 0.113143190741539\n",
      "[*] Test roc_auc: 0.4557543512611555\n",
      "\n",
      "[*] Best val loss: 0.09997007995843887 at epoch 2\n",
      "[*] Best Val ROC AUC: 0.4381816036513252 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.4563852551774107 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 3...\n",
      "[*] Training Loss: 0.1450994461774826\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.009716293774545193\n",
      "mean sig(logit) neg = 0.009828684851527214\n",
      "mean logit pos = -5.013886451721191\n",
      "mean logit neg = -5.107738971710205\n",
      "[*] Val Loss: 0.09195656329393387\n",
      "[*] Val roc_auc: 0.5286040150812512\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.009998220950365067\n",
      "mean sig(logit) neg = 0.010390451177954674\n",
      "mean logit pos = -5.01184606552124\n",
      "mean logit neg = -5.127111434936523\n",
      "[*] Test Loss: 0.10479407757520676\n",
      "[*] Test roc_auc: 0.532792645056241\n",
      "\n",
      "[*] Best val loss: 0.09195656329393387 at epoch 3\n",
      "[*] Best Val ROC AUC: 0.5286040150812512 at epoch 3\n",
      "[*] Best Test ROC AUC: 0.532792645056241 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 4...\n",
      "[*] Training Loss: 0.11509896069765091\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.03516059368848801\n",
      "mean sig(logit) neg = 0.014070792123675346\n",
      "mean logit pos = -3.9955406188964844\n",
      "mean logit neg = -4.726694107055664\n",
      "[*] Val Loss: 0.07982689887285233\n",
      "[*] Val roc_auc: 0.6717012430570912\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.031148836016654968\n",
      "mean sig(logit) neg = 0.013553760945796967\n",
      "mean logit pos = -4.098006248474121\n",
      "mean logit neg = -4.795452117919922\n",
      "[*] Test Loss: 0.09073885530233383\n",
      "[*] Test roc_auc: 0.6631655432319323\n",
      "\n",
      "[*] Best val loss: 0.07982689887285233 at epoch 4\n",
      "[*] Best Val ROC AUC: 0.6717012430570912 at epoch 4\n",
      "[*] Best Test ROC AUC: 0.6631655432319323 at epoch 4\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 5...\n",
      "[*] Training Loss: 0.09930646419525146\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.04901086539030075\n",
      "mean sig(logit) neg = 0.014000941067934036\n",
      "mean logit pos = -3.811225414276123\n",
      "mean logit neg = -4.74457311630249\n",
      "[*] Val Loss: 0.07649972289800644\n",
      "[*] Val roc_auc: 0.6906589106860976\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.04065539315342903\n",
      "mean sig(logit) neg = 0.01278135646134615\n",
      "mean logit pos = -3.9739346504211426\n",
      "mean logit neg = -4.8358941078186035\n",
      "[*] Test Loss: 0.08709168434143066\n",
      "[*] Test roc_auc: 0.6837563451697425\n",
      "\n",
      "[*] Best val loss: 0.07649972289800644 at epoch 5\n",
      "[*] Best Val ROC AUC: 0.6906589106860976 at epoch 5\n",
      "[*] Best Test ROC AUC: 0.6837563451697425 at epoch 5\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 6...\n",
      "[*] Training Loss: 0.09393053501844406\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.05675014853477478\n",
      "mean sig(logit) neg = 0.015068159438669682\n",
      "mean logit pos = -3.640058994293213\n",
      "mean logit neg = -4.631968021392822\n",
      "[*] Val Loss: 0.07460324466228485\n",
      "[*] Val roc_auc: 0.7039805995564683\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.046124689280986786\n",
      "mean sig(logit) neg = 0.013552209362387657\n",
      "mean logit pos = -3.8294358253479004\n",
      "mean logit neg = -4.726824760437012\n",
      "[*] Test Loss: 0.08482971787452698\n",
      "[*] Test roc_auc: 0.6954881239797988\n",
      "\n",
      "[*] Best val loss: 0.07460324466228485 at epoch 6\n",
      "[*] Best Val ROC AUC: 0.7039805995564683 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.6954881239797988 at epoch 6\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 7...\n",
      "[*] Training Loss: 0.09061545133590698\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.059639520943164825\n",
      "mean sig(logit) neg = 0.014899416826665401\n",
      "mean logit pos = -3.5875372886657715\n",
      "mean logit neg = -4.628275394439697\n",
      "[*] Val Loss: 0.073361836373806\n",
      "[*] Val roc_auc: 0.7154940712024767\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.04755283147096634\n",
      "mean sig(logit) neg = 0.013349596410989761\n",
      "mean logit pos = -3.7882537841796875\n",
      "mean logit neg = -4.7191009521484375\n",
      "[*] Test Loss: 0.0835086777806282\n",
      "[*] Test roc_auc: 0.7066747992466361\n",
      "\n",
      "[*] Best val loss: 0.073361836373806 at epoch 7\n",
      "[*] Best Val ROC AUC: 0.7154940712024767 at epoch 7\n",
      "[*] Best Test ROC AUC: 0.7066747992466361 at epoch 7\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 8...\n",
      "[*] Training Loss: 0.08829054981470108\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0668824315071106\n",
      "mean sig(logit) neg = 0.01604587584733963\n",
      "mean logit pos = -3.4643633365631104\n",
      "mean logit neg = -4.538970947265625\n",
      "[*] Val Loss: 0.07257966697216034\n",
      "[*] Val roc_auc: 0.7232514032973856\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.05289314314723015\n",
      "mean sig(logit) neg = 0.01424866821616888\n",
      "mean logit pos = -3.671583652496338\n",
      "mean logit neg = -4.635015487670898\n",
      "[*] Test Loss: 0.08217769861221313\n",
      "[*] Test roc_auc: 0.7175307119294342\n",
      "\n",
      "[*] Best val loss: 0.07257966697216034 at epoch 8\n",
      "[*] Best Val ROC AUC: 0.7232514032973856 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.7175307119294342 at epoch 8\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 9...\n",
      "[*] Training Loss: 0.08656603842973709\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.06830909848213196\n",
      "mean sig(logit) neg = 0.015507816337049007\n",
      "mean logit pos = -3.4513893127441406\n",
      "mean logit neg = -4.573528289794922\n",
      "[*] Val Loss: 0.07172074913978577\n",
      "[*] Val roc_auc: 0.7343713319297025\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.052643757313489914\n",
      "mean sig(logit) neg = 0.013822459615767002\n",
      "mean logit pos = -3.672393798828125\n",
      "mean logit neg = -4.657412528991699\n",
      "[*] Test Loss: 0.08155400305986404\n",
      "[*] Test roc_auc: 0.7231120671642355\n",
      "\n",
      "[*] Best val loss: 0.07172074913978577 at epoch 9\n",
      "[*] Best Val ROC AUC: 0.7343713319297025 at epoch 9\n",
      "[*] Best Test ROC AUC: 0.7231120671642355 at epoch 9\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 10...\n",
      "[*] Training Loss: 0.08550404012203217\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.07481826096773148\n",
      "mean sig(logit) neg = 0.01647241599857807\n",
      "mean logit pos = -3.3562374114990234\n",
      "mean logit neg = -4.507293224334717\n",
      "[*] Val Loss: 0.07129316031932831\n",
      "[*] Val roc_auc: 0.7414650558967121\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.05770590528845787\n",
      "mean sig(logit) neg = 0.014621375128626823\n",
      "mean logit pos = -3.5702552795410156\n",
      "mean logit neg = -4.593870162963867\n",
      "[*] Test Loss: 0.08050649613142014\n",
      "[*] Test roc_auc: 0.733273507959996\n",
      "\n",
      "[*] Best val loss: 0.07129316031932831 at epoch 10\n",
      "[*] Best Val ROC AUC: 0.7414650558967121 at epoch 10\n",
      "[*] Best Test ROC AUC: 0.733273507959996 at epoch 10\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 11...\n",
      "[*] Training Loss: 0.08459386229515076\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.07512646168470383\n",
      "mean sig(logit) neg = 0.015763504430651665\n",
      "mean logit pos = -3.3735809326171875\n",
      "mean logit neg = -4.557183265686035\n",
      "[*] Val Loss: 0.0708034560084343\n",
      "[*] Val roc_auc: 0.746606411727973\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.057083580642938614\n",
      "mean sig(logit) neg = 0.01382994744926691\n",
      "mean logit pos = -3.602663278579712\n",
      "mean logit neg = -4.649570465087891\n",
      "[*] Test Loss: 0.08018413931131363\n",
      "[*] Test roc_auc: 0.7385710547576029\n",
      "\n",
      "[*] Best val loss: 0.0708034560084343 at epoch 11\n",
      "[*] Best Val ROC AUC: 0.746606411727973 at epoch 11\n",
      "[*] Best Test ROC AUC: 0.7385710547576029 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 12...\n",
      "[*] Training Loss: 0.08387050032615662\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0782768577337265\n",
      "mean sig(logit) neg = 0.01605861261487007\n",
      "mean logit pos = -3.331289291381836\n",
      "mean logit neg = -4.538814067840576\n",
      "[*] Val Loss: 0.07050999999046326\n",
      "[*] Val roc_auc: 0.7508607930949829\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.059538036584854126\n",
      "mean sig(logit) neg = 0.01401892863214016\n",
      "mean logit pos = -3.5634875297546387\n",
      "mean logit neg = -4.633764266967773\n",
      "[*] Test Loss: 0.07968294620513916\n",
      "[*] Test roc_auc: 0.7429382040039612\n",
      "\n",
      "[*] Best val loss: 0.07050999999046326 at epoch 12\n",
      "[*] Best Val ROC AUC: 0.7508607930949829 at epoch 12\n",
      "[*] Best Test ROC AUC: 0.7429382040039612 at epoch 12\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 13...\n",
      "[*] Training Loss: 0.08328557014465332\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08070040494203568\n",
      "mean sig(logit) neg = 0.01618727296590805\n",
      "mean logit pos = -3.300567150115967\n",
      "mean logit neg = -4.532956600189209\n",
      "[*] Val Loss: 0.07021960616111755\n",
      "[*] Val roc_auc: 0.7564106654246855\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.061485446989536285\n",
      "mean sig(logit) neg = 0.014067290350794792\n",
      "mean logit pos = -3.5366601943969727\n",
      "mean logit neg = -4.631511211395264\n",
      "[*] Test Loss: 0.07927621901035309\n",
      "[*] Test roc_auc: 0.7469081431741109\n",
      "\n",
      "[*] Best val loss: 0.07021960616111755 at epoch 13\n",
      "[*] Best Val ROC AUC: 0.7564106654246855 at epoch 13\n",
      "[*] Best Test ROC AUC: 0.7469081431741109 at epoch 13\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 14...\n",
      "[*] Training Loss: 0.08278309553861618\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08282830566167831\n",
      "mean sig(logit) neg = 0.016266467049717903\n",
      "mean logit pos = -3.278904914855957\n",
      "mean logit neg = -4.5349955558776855\n",
      "[*] Val Loss: 0.07002289593219757\n",
      "[*] Val roc_auc: 0.759876867095296\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06272754073143005\n",
      "mean sig(logit) neg = 0.01405565720051527\n",
      "mean logit pos = -3.5232057571411133\n",
      "mean logit neg = -4.63674783706665\n",
      "[*] Test Loss: 0.07905854284763336\n",
      "[*] Test roc_auc: 0.7502923533583834\n",
      "\n",
      "[*] Best val loss: 0.07002289593219757 at epoch 14\n",
      "[*] Best Val ROC AUC: 0.759876867095296 at epoch 14\n",
      "[*] Best Test ROC AUC: 0.7502923533583834 at epoch 14\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 15...\n",
      "[*] Training Loss: 0.08240333199501038\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08277308195829391\n",
      "mean sig(logit) neg = 0.015951812267303467\n",
      "mean logit pos = -3.2852745056152344\n",
      "mean logit neg = -4.560713291168213\n",
      "[*] Val Loss: 0.06980271637439728\n",
      "[*] Val roc_auc: 0.7630098109224103\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06275969743728638\n",
      "mean sig(logit) neg = 0.013741770759224892\n",
      "mean logit pos = -3.5316991806030273\n",
      "mean logit neg = -4.664393424987793\n",
      "[*] Test Loss: 0.07889096438884735\n",
      "[*] Test roc_auc: 0.7530697336737692\n",
      "\n",
      "[*] Best val loss: 0.06980271637439728 at epoch 15\n",
      "[*] Best Val ROC AUC: 0.7630098109224103 at epoch 15\n",
      "[*] Best Test ROC AUC: 0.7530697336737692 at epoch 15\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 16...\n",
      "[*] Training Loss: 0.08201593905687332\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08259876817464828\n",
      "mean sig(logit) neg = 0.015654306858778\n",
      "mean logit pos = -3.2953484058380127\n",
      "mean logit neg = -4.587280750274658\n",
      "[*] Val Loss: 0.0696554183959961\n",
      "[*] Val roc_auc: 0.765714863415411\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06260946393013\n",
      "mean sig(logit) neg = 0.013428677804768085\n",
      "mean logit pos = -3.5465199947357178\n",
      "mean logit neg = -4.693836212158203\n",
      "[*] Test Loss: 0.07883749902248383\n",
      "[*] Test roc_auc: 0.7547412529192417\n",
      "\n",
      "[*] Best val loss: 0.0696554183959961 at epoch 16\n",
      "[*] Best Val ROC AUC: 0.765714863415411 at epoch 16\n",
      "[*] Best Test ROC AUC: 0.7547412529192417 at epoch 16\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 17...\n",
      "[*] Training Loss: 0.08166150748729706\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.085587278008461\n",
      "mean sig(logit) neg = 0.016101224347949028\n",
      "mean logit pos = -3.255855083465576\n",
      "mean logit neg = -4.565213203430176\n",
      "[*] Val Loss: 0.06958144158124924\n",
      "[*] Val roc_auc: 0.7680776597474763\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06513377279043198\n",
      "mean sig(logit) neg = 0.013775554485619068\n",
      "mean logit pos = -3.508395195007324\n",
      "mean logit neg = -4.674233436584473\n",
      "[*] Test Loss: 0.07857754081487656\n",
      "[*] Test roc_auc: 0.7568039500728136\n",
      "\n",
      "[*] Best val loss: 0.06958144158124924 at epoch 17\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7680776597474763 at epoch 17\n",
      "[*] Best Test ROC AUC: 0.7568039500728136 at epoch 17\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 18...\n",
      "[*] Training Loss: 0.0813361331820488\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08328486979007721\n",
      "mean sig(logit) neg = 0.015315009281039238\n",
      "mean logit pos = -3.301626682281494\n",
      "mean logit neg = -4.628085136413574\n",
      "[*] Val Loss: 0.0694383829832077\n",
      "[*] Val roc_auc: 0.769877945648562\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06329195946455002\n",
      "mean sig(logit) neg = 0.0130449328571558\n",
      "mean logit pos = -3.558042049407959\n",
      "mean logit neg = -4.7399444580078125\n",
      "[*] Test Loss: 0.07867896556854248\n",
      "[*] Test roc_auc: 0.757941993110749\n",
      "\n",
      "[*] Best val loss: 0.0694383829832077 at epoch 18\n",
      "[*] Best Val ROC AUC: 0.769877945648562 at epoch 18\n",
      "[*] Best Test ROC AUC: 0.757941993110749 at epoch 18\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 19...\n",
      "[*] Training Loss: 0.08103717118501663\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08787701278924942\n",
      "mean sig(logit) neg = 0.016252810135483742\n",
      "mean logit pos = -3.232638120651245\n",
      "mean logit neg = -4.571232318878174\n",
      "[*] Val Loss: 0.06944835931062698\n",
      "[*] Val roc_auc: 0.7716294521331747\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06724894791841507\n",
      "mean sig(logit) neg = 0.013834175653755665\n",
      "mean logit pos = -3.4890124797821045\n",
      "mean logit neg = -4.684543609619141\n",
      "[*] Test Loss: 0.07835391908884048\n",
      "[*] Test roc_auc: 0.7590392780451491\n",
      "\n",
      "[*] Best val loss: 0.0694383829832077 at epoch 18\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.769877945648562 at epoch 18\n",
      "[*] Best Test ROC AUC: 0.7590392780451491 at epoch 19\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 20...\n",
      "[*] Training Loss: 0.08077019453048706\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08561568707227707\n",
      "mean sig(logit) neg = 0.01557192299515009\n",
      "mean logit pos = -3.274390935897827\n",
      "mean logit neg = -4.625763893127441\n",
      "[*] Val Loss: 0.06934833526611328\n",
      "[*] Val roc_auc: 0.7726916626054202\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06550800800323486\n",
      "mean sig(logit) neg = 0.013208270072937012\n",
      "mean logit pos = -3.5335028171539307\n",
      "mean logit neg = -4.741393089294434\n",
      "[*] Test Loss: 0.0784701481461525\n",
      "[*] Test roc_auc: 0.7593893310814072\n",
      "\n",
      "[*] Best val loss: 0.06934833526611328 at epoch 20\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.7726916626054202 at epoch 20\n",
      "[*] Best Test ROC AUC: 0.7593893310814072 at epoch 20\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 21...\n",
      "[*] Training Loss: 0.08049172163009644\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08927920460700989\n",
      "mean sig(logit) neg = 0.0163338053971529\n",
      "mean logit pos = -3.220397710800171\n",
      "mean logit neg = -4.5818095207214355\n",
      "[*] Val Loss: 0.06938982754945755\n",
      "[*] Val roc_auc: 0.7738097302220851\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06880533695220947\n",
      "mean sig(logit) neg = 0.013853037729859352\n",
      "mean logit pos = -3.4786558151245117\n",
      "mean logit neg = -4.6984028816223145\n",
      "[*] Test Loss: 0.07823657989501953\n",
      "[*] Test roc_auc: 0.7597817731696279\n",
      "\n",
      "[*] Best val loss: 0.06934833526611328 at epoch 20\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.7726916626054202 at epoch 20\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 22...\n",
      "[*] Training Loss: 0.08025041967630386\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08717633038759232\n",
      "mean sig(logit) neg = 0.015731576830148697\n",
      "mean logit pos = -3.2582404613494873\n",
      "mean logit neg = -4.630571365356445\n",
      "[*] Val Loss: 0.06931135058403015\n",
      "[*] Val roc_auc: 0.7745027340391678\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06725440174341202\n",
      "mean sig(logit) neg = 0.013305696658790112\n",
      "mean logit pos = -3.518620491027832\n",
      "mean logit neg = -4.749051570892334\n",
      "[*] Test Loss: 0.07835625857114792\n",
      "[*] Test roc_auc: 0.75964025522829\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 16 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 23...\n",
      "[*] Training Loss: 0.08000073581933975\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0896410197019577\n",
      "mean sig(logit) neg = 0.01623600907623768\n",
      "mean logit pos = -3.223686695098877\n",
      "mean logit neg = -4.604503631591797\n",
      "[*] Val Loss: 0.06936164945363998\n",
      "[*] Val roc_auc: 0.7750289666686139\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06959408521652222\n",
      "mean sig(logit) neg = 0.013731309212744236\n",
      "mean logit pos = -3.483466386795044\n",
      "mean logit neg = -4.723788738250732\n",
      "[*] Test Loss: 0.07822781056165695\n",
      "[*] Test roc_auc: 0.7594783855477181\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 15 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 24...\n",
      "[*] Training Loss: 0.07975929230451584\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0905403196811676\n",
      "mean sig(logit) neg = 0.016370363533496857\n",
      "mean logit pos = -3.2143681049346924\n",
      "mean logit neg = -4.603702068328857\n",
      "[*] Val Loss: 0.06938601285219193\n",
      "[*] Val roc_auc: 0.7754234166273435\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.0706227570772171\n",
      "mean sig(logit) neg = 0.013824271969497204\n",
      "mean logit pos = -3.475294828414917\n",
      "mean logit neg = -4.724567413330078\n",
      "[*] Test Loss: 0.0782093033194542\n",
      "[*] Test roc_auc: 0.7591338028217375\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 14 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 25...\n",
      "[*] Training Loss: 0.0795435830950737\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09156692773103714\n",
      "mean sig(logit) neg = 0.016610946506261826\n",
      "mean logit pos = -3.200124740600586\n",
      "mean logit neg = -4.594459533691406\n",
      "[*] Val Loss: 0.06944122910499573\n",
      "[*] Val roc_auc: 0.7755365357918301\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07174602150917053\n",
      "mean sig(logit) neg = 0.01402786560356617\n",
      "mean logit pos = -3.4619929790496826\n",
      "mean logit neg = -4.716050624847412\n",
      "[*] Test Loss: 0.07821202278137207\n",
      "[*] Test roc_auc: 0.7582283611225095\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 13 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 26...\n",
      "[*] Training Loss: 0.07933934777975082\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09083513170480728\n",
      "mean sig(logit) neg = 0.016348563134670258\n",
      "mean logit pos = -3.216762065887451\n",
      "mean logit neg = -4.620213031768799\n",
      "[*] Val Loss: 0.06941681355237961\n",
      "[*] Val roc_auc: 0.7755674074896054\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.0713835135102272\n",
      "mean sig(logit) neg = 0.013787029311060905\n",
      "mean logit pos = -3.4801385402679443\n",
      "mean logit neg = -4.743125915527344\n",
      "[*] Test Loss: 0.07828623801469803\n",
      "[*] Test roc_auc: 0.7578532351805158\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 12 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 27...\n",
      "[*] Training Loss: 0.0791139006614685\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08985111117362976\n",
      "mean sig(logit) neg = 0.016093844547867775\n",
      "mean logit pos = -3.2360243797302246\n",
      "mean logit neg = -4.645091533660889\n",
      "[*] Val Loss: 0.06943419575691223\n",
      "[*] Val roc_auc: 0.7752490164314434\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.0708102285861969\n",
      "mean sig(logit) neg = 0.013554160483181477\n",
      "mean logit pos = -3.5014617443084717\n",
      "mean logit neg = -4.76936674118042\n",
      "[*] Test Loss: 0.07841840386390686\n",
      "[*] Test roc_auc: 0.7567717915155348\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 11 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 28...\n",
      "[*] Training Loss: 0.07890242338180542\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09222415089607239\n",
      "mean sig(logit) neg = 0.01661461777985096\n",
      "mean logit pos = -3.204594373703003\n",
      "mean logit neg = -4.618403434753418\n",
      "[*] Val Loss: 0.06955217570066452\n",
      "[*] Val roc_auc: 0.7747957306362566\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.0731443241238594\n",
      "mean sig(logit) neg = 0.013997681438922882\n",
      "mean logit pos = -3.4701461791992188\n",
      "mean logit neg = -4.743380069732666\n",
      "[*] Test Loss: 0.07838092744350433\n",
      "[*] Test roc_auc: 0.7557452460428509\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 10 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 29...\n",
      "[*] Training Loss: 0.07868516445159912\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08906275033950806\n",
      "mean sig(logit) neg = 0.01582658663392067\n",
      "mean logit pos = -3.2602012157440186\n",
      "mean logit neg = -4.679988861083984\n",
      "[*] Val Loss: 0.06953005492687225\n",
      "[*] Val roc_auc: 0.7740214929969171\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.070701003074646\n",
      "mean sig(logit) neg = 0.013303127139806747\n",
      "mean logit pos = -3.5283944606781006\n",
      "mean logit neg = -4.806588649749756\n",
      "[*] Test Loss: 0.0786522701382637\n",
      "[*] Test roc_auc: 0.7542984777336055\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 9 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 30...\n",
      "[*] Training Loss: 0.07847235351800919\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0931672528386116\n",
      "mean sig(logit) neg = 0.01675509475171566\n",
      "mean logit pos = -3.202160358428955\n",
      "mean logit neg = -4.625884532928467\n",
      "[*] Val Loss: 0.06969983875751495\n",
      "[*] Val roc_auc: 0.7733282313229117\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07445435225963593\n",
      "mean sig(logit) neg = 0.014102334156632423\n",
      "mean logit pos = -3.469435214996338\n",
      "mean logit neg = -4.752823829650879\n",
      "[*] Test Loss: 0.07852370291948318\n",
      "[*] Test roc_auc: 0.7533313175122909\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 8 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 31...\n",
      "[*] Training Loss: 0.07826507836580276\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09022759646177292\n",
      "mean sig(logit) neg = 0.016050919890403748\n",
      "mean logit pos = -3.252246618270874\n",
      "mean logit neg = -4.680251598358154\n",
      "[*] Val Loss: 0.06968114525079727\n",
      "[*] Val roc_auc: 0.7725144704414608\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07215726375579834\n",
      "mean sig(logit) neg = 0.013477596454322338\n",
      "mean logit pos = -3.5213191509246826\n",
      "mean logit neg = -4.808985233306885\n",
      "[*] Test Loss: 0.07875373959541321\n",
      "[*] Test roc_auc: 0.752128333073318\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 7 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 32...\n",
      "[*] Training Loss: 0.07802636921405792\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09334853291511536\n",
      "mean sig(logit) neg = 0.016753481701016426\n",
      "mean logit pos = -3.209953546524048\n",
      "mean logit neg = -4.642594814300537\n",
      "[*] Val Loss: 0.06984060257673264\n",
      "[*] Val roc_auc: 0.771843606753255\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07509878277778625\n",
      "mean sig(logit) neg = 0.014076841063797474\n",
      "mean logit pos = -3.477278470993042\n",
      "mean logit neg = -4.772090911865234\n",
      "[*] Test Loss: 0.07866662740707397\n",
      "[*] Test roc_auc: 0.7515046474694829\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 6 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 33...\n",
      "[*] Training Loss: 0.07780684530735016\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0907176285982132\n",
      "mean sig(logit) neg = 0.016098544001579285\n",
      "mean logit pos = -3.25596284866333\n",
      "mean logit neg = -4.694715976715088\n",
      "[*] Val Loss: 0.06981809437274933\n",
      "[*] Val roc_auc: 0.7712910816093153\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07301580160856247\n",
      "mean sig(logit) neg = 0.01348944567143917\n",
      "mean logit pos = -3.5244314670562744\n",
      "mean logit neg = -4.826397895812988\n",
      "[*] Test Loss: 0.078855961561203\n",
      "[*] Test roc_auc: 0.7509511472731135\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 5 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 34...\n",
      "[*] Training Loss: 0.07756729423999786\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09293162822723389\n",
      "mean sig(logit) neg = 0.016561709344387054\n",
      "mean logit pos = -3.229015588760376\n",
      "mean logit neg = -4.674431324005127\n",
      "[*] Val Loss: 0.06994863599538803\n",
      "[*] Val roc_auc: 0.7706808142979351\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07520397752523422\n",
      "mean sig(logit) neg = 0.01388341560959816\n",
      "mean logit pos = -3.494075298309326\n",
      "mean logit neg = -4.806891918182373\n",
      "[*] Test Loss: 0.07878469675779343\n",
      "[*] Test roc_auc: 0.7510505648949853\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 4 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 35...\n",
      "[*] Training Loss: 0.07733973115682602\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09327704459428787\n",
      "mean sig(logit) neg = 0.016602134332060814\n",
      "mean logit pos = -3.2297117710113525\n",
      "mean logit neg = -4.68154239654541\n",
      "[*] Val Loss: 0.0700230747461319\n",
      "[*] Val roc_auc: 0.7703373844434208\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07570789754390717\n",
      "mean sig(logit) neg = 0.013885031454265118\n",
      "mean logit pos = -3.4953367710113525\n",
      "mean logit neg = -4.816379547119141\n",
      "[*] Test Loss: 0.07883058488368988\n",
      "[*] Test roc_auc: 0.7506675729433491\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 3 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 36...\n",
      "[*] Training Loss: 0.07711479812860489\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09414508938789368\n",
      "mean sig(logit) neg = 0.016806280240416527\n",
      "mean logit pos = -3.2216498851776123\n",
      "mean logit neg = -4.6777873039245605\n",
      "[*] Val Loss: 0.07014121115207672\n",
      "[*] Val roc_auc: 0.7695838998405466\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.0766712948679924\n",
      "mean sig(logit) neg = 0.014038232155144215\n",
      "mean logit pos = -3.4874184131622314\n",
      "mean logit neg = -4.814565181732178\n",
      "[*] Test Loss: 0.07887843251228333\n",
      "[*] Test roc_auc: 0.7497336013520047\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 2 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 37...\n",
      "[*] Training Loss: 0.07688434422016144\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09308008849620819\n",
      "mean sig(logit) neg = 0.016482049599289894\n",
      "mean logit pos = -3.2453134059906006\n",
      "mean logit neg = -4.709455490112305\n",
      "[*] Val Loss: 0.07015346735715866\n",
      "[*] Val roc_auc: 0.7691050417519263\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07593189924955368\n",
      "mean sig(logit) neg = 0.013746222481131554\n",
      "mean logit pos = -3.511428117752075\n",
      "mean logit neg = -4.84791898727417\n",
      "[*] Test Loss: 0.07899479568004608\n",
      "[*] Test roc_auc: 0.7494382904364244\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 1 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 38...\n",
      "[*] Training Loss: 0.07664728909730911\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09243962913751602\n",
      "mean sig(logit) neg = 0.016293363645672798\n",
      "mean logit pos = -3.2620348930358887\n",
      "mean logit neg = -4.732962608337402\n",
      "[*] Val Loss: 0.0702105388045311\n",
      "[*] Val roc_auc: 0.7684166349013613\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07561025023460388\n",
      "mean sig(logit) neg = 0.01356707327067852\n",
      "mean logit pos = -3.52839994430542\n",
      "mean logit neg = -4.873273849487305\n",
      "[*] Test Loss: 0.07911220192909241\n",
      "[*] Test roc_auc: 0.7487924816804693\n",
      "\n",
      "[*] Best val loss: 0.06931135058403015 at epoch 22\n",
      "[*] Early stopping in 0 epochs\n",
      "[*] Best Val ROC AUC: 0.7745027340391678 at epoch 22\n",
      "[*] Best Test ROC AUC: 0.7597817731696279 at epoch 21\n",
      "-----------------------------------------------------\n",
      "[*] Early stopping\n",
      "\n",
      "[*] ----------------------------- Iteration: 1 -----------------------------\n",
      "\n",
      "[*] Trial: <optuna.trial._trial.Trial object at 0x780195f7a0c0>\n",
      "[*] HPT: {'memory': 5, 'seed': 43, 'num_layers': 6, 'state_size': 32, 'd_model_factor': 1.0, 'dropout': 0.08247365455773248, 'pos_weight': 3.710016914668122, 'batch_size': 64, 'n_accumulation_steps': 6, 'learning_rate': 0.002748609339853579, 'rec_learning_factor': 0.5, 'beta1': 0.9295105328282061, 'beta2': 0.9700120100701175, 'weight_decay': 0.0017878732133620805}\n",
      "[*] Npz file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists with matching meta. Using existing file.\n",
      "\n",
      "[*] -------------------- Dataset Statistics --------------------\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz\n",
      "[*] Number of nodes: 7047\n",
      "[*] Total number of edges used: 411648\n",
      "[*] Val_ratio: 0.2 | Test_ratio: 0.2\n",
      "[*] Number of features: 6\n",
      "[*] -----------------------------------------------------------\n",
      "\n",
      "[*] Trainable Parameters: 64769\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- decoder\n",
      "|  |  |  |- bias  shape=(1,)\n",
      "|  |  |  |- kernel  shape=(32, 1)\n",
      "|  |  |- encoder\n",
      "|  |     |- encoder\n",
      "|  |     |  |- bias  shape=(32,)\n",
      "|  |     |  |- kernel  shape=(6, 32)\n",
      "|  |     |- layers_0\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_1\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_2\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_3\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_4\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_5\n",
      "|  |        |- norm\n",
      "|  |        |  |- bias  shape=(32,)\n",
      "|  |        |  |- scale  shape=(32,)\n",
      "|  |        |- out1\n",
      "|  |        |  |- bias  shape=(32,)\n",
      "|  |        |  |- kernel  shape=(32, 32)\n",
      "|  |        |- out2\n",
      "|  |        |  |- bias  shape=(32,)\n",
      "|  |        |  |- kernel  shape=(32, 32)\n",
      "|  |        |- seq\n",
      "|  |           |- B_im  shape=(64, 32)\n",
      "|  |           |- B_re  shape=(64, 32)\n",
      "|  |           |- C_im  shape=(32, 64)\n",
      "|  |           |- C_re  shape=(32, 64)\n",
      "|  |           |- D  shape=(32,)\n",
      "|  |           |- gamma_log  shape=(64,)\n",
      "|  |           |- nu  shape=(128,)\n",
      "|  |           |- phi  shape=(32,)\n",
      "|  |           |- theta  shape=(128,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64, 64)\n",
      "|        |- layers_1\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64, 64)\n",
      "|        |- layers_2\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64, 64)\n",
      "|        |- layers_3\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64, 64)\n",
      "|        |- layers_4\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64, 64)\n",
      "|        |- layers_5\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(64, 64)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py:5518: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "[*] Training Loss: 0.20851068198680878\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09119386225938797\n",
      "mean sig(logit) neg = 0.020149359479546547\n",
      "mean logit pos = -3.131234884262085\n",
      "mean logit neg = -4.441262245178223\n",
      "[*] Val Loss: 0.12282729893922806\n",
      "[*] Val roc_auc: 0.7559125836578995\n",
      "\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06286101788282394\n",
      "mean sig(logit) neg = 0.01339257974177599\n",
      "mean logit pos = -3.7183916568756104\n",
      "mean logit neg = -4.875298500061035\n",
      "[*] Test Loss: 0.14965975284576416\n",
      "[*] Test roc_auc: 0.7273850740094743\n",
      "\n",
      "[*] Best val loss: 0.12282729893922806 at epoch 1\n",
      "[*] Best Val ROC AUC: 0.7559125836578995 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.7273850740094743 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 2...\n",
      "[*] Training Loss: 0.14883281290531158\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.12115522474050522\n",
      "mean sig(logit) neg = 0.02786277048289776\n",
      "mean logit pos = -2.6929681301116943\n",
      "mean logit neg = -4.04966926574707\n",
      "[*] Val Loss: 0.11742711067199707\n",
      "[*] Val roc_auc: 0.775517045365124\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.08130251616239548\n",
      "mean sig(logit) neg = 0.0172604788094759\n",
      "mean logit pos = -3.348372220993042\n",
      "mean logit neg = -4.552248477935791\n",
      "[*] Test Loss: 0.13979874551296234\n",
      "[*] Test roc_auc: 0.7431005184886499\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7431005184886499 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 3...\n",
      "[*] Training Loss: 0.1441495418548584\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.06991179287433624\n",
      "mean sig(logit) neg = 0.014372977428138256\n",
      "mean logit pos = -3.3966593742370605\n",
      "mean logit neg = -4.7400407791137695\n",
      "[*] Val Loss: 0.1226407065987587\n",
      "[*] Val roc_auc: 0.7783353859633539\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.04282277822494507\n",
      "mean sig(logit) neg = 0.008417547680437565\n",
      "mean logit pos = -4.078859329223633\n",
      "mean logit neg = -5.272313117980957\n",
      "[*] Test Loss: 0.15470878779888153\n",
      "[*] Test roc_auc: 0.7493315530555795\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 4...\n",
      "[*] Training Loss: 0.14293698966503143\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09522705525159836\n",
      "mean sig(logit) neg = 0.021447738632559776\n",
      "mean logit pos = -2.9924423694610596\n",
      "mean logit neg = -4.297015190124512\n",
      "[*] Val Loss: 0.11863287538290024\n",
      "[*] Val roc_auc: 0.7736440971615555\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.05550652742385864\n",
      "mean sig(logit) neg = 0.010992521420121193\n",
      "mean logit pos = -3.8343868255615234\n",
      "mean logit neg = -5.050945281982422\n",
      "[*] Test Loss: 0.14930042624473572\n",
      "[*] Test roc_auc: 0.7391158617647443\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 5...\n",
      "[*] Training Loss: 0.14287464320659637\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.0904107466340065\n",
      "mean sig(logit) neg = 0.017497127875685692\n",
      "mean logit pos = -3.1725594997406006\n",
      "mean logit neg = -4.63206672668457\n",
      "[*] Val Loss: 0.12003085762262344\n",
      "[*] Val roc_auc: 0.7778279857808801\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.05223360285162926\n",
      "mean sig(logit) neg = 0.009090735577046871\n",
      "mean logit pos = -4.039746284484863\n",
      "mean logit neg = -5.323487281799316\n",
      "[*] Test Loss: 0.15455381572246552\n",
      "[*] Test roc_auc: 0.7407090174498685\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 6...\n",
      "[*] Training Loss: 0.1421864926815033\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08642738312482834\n",
      "mean sig(logit) neg = 0.019280388951301575\n",
      "mean logit pos = -3.102388858795166\n",
      "mean logit neg = -4.434674263000488\n",
      "[*] Val Loss: 0.11935719102621078\n",
      "[*] Val roc_auc: 0.7769907065697585\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.05317365750670433\n",
      "mean sig(logit) neg = 0.011426153592765331\n",
      "mean logit pos = -3.823803186416626\n",
      "mean logit neg = -4.971670150756836\n",
      "[*] Test Loss: 0.1492314636707306\n",
      "[*] Test roc_auc: 0.7382529105640323\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 16 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 7...\n",
      "[*] Training Loss: 0.14270725846290588\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.08744145929813385\n",
      "mean sig(logit) neg = 0.018154289573431015\n",
      "mean logit pos = -3.252781867980957\n",
      "mean logit neg = -4.79890251159668\n",
      "[*] Val Loss: 0.12309086322784424\n",
      "[*] Val roc_auc: 0.7624875795210744\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.03804272040724754\n",
      "mean sig(logit) neg = 0.005653436295688152\n",
      "mean logit pos = -4.856460094451904\n",
      "mean logit neg = -6.556915283203125\n",
      "[*] Test Loss: 0.17935441434383392\n",
      "[*] Test roc_auc: 0.7293808164381121\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 15 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 8...\n",
      "[*] Training Loss: 0.14234031736850739\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.10266385972499847\n",
      "mean sig(logit) neg = 0.02222309820353985\n",
      "mean logit pos = -2.9345014095306396\n",
      "mean logit neg = -4.321718692779541\n",
      "[*] Val Loss: 0.11804977804422379\n",
      "[*] Val roc_auc: 0.7760620926583066\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06405531615018845\n",
      "mean sig(logit) neg = 0.012864960357546806\n",
      "mean logit pos = -3.6618547439575195\n",
      "mean logit neg = -4.9287896156311035\n",
      "[*] Test Loss: 0.14549720287322998\n",
      "[*] Test roc_auc: 0.7408278659884169\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 14 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 9...\n",
      "[*] Training Loss: 0.14234189689159393\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.11027026176452637\n",
      "mean sig(logit) neg = 0.022857697680592537\n",
      "mean logit pos = -2.8873183727264404\n",
      "mean logit neg = -4.359786510467529\n",
      "[*] Val Loss: 0.11773348599672318\n",
      "[*] Val roc_auc: 0.7772538806799989\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07679689675569534\n",
      "mean sig(logit) neg = 0.014978062361478806\n",
      "mean logit pos = -3.507006883621216\n",
      "mean logit neg = -4.808424949645996\n",
      "[*] Test Loss: 0.1428561508655548\n",
      "[*] Test roc_auc: 0.7415371334650203\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 13 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 10...\n",
      "[*] Training Loss: 0.14237534999847412\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.10207020491361618\n",
      "mean sig(logit) neg = 0.022069843485951424\n",
      "mean logit pos = -2.9593467712402344\n",
      "mean logit neg = -4.327373504638672\n",
      "[*] Val Loss: 0.11853770166635513\n",
      "[*] Val roc_auc: 0.7703117054505708\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07186520099639893\n",
      "mean sig(logit) neg = 0.015627002343535423\n",
      "mean logit pos = -3.4792511463165283\n",
      "mean logit neg = -4.695310115814209\n",
      "[*] Test Loss: 0.1422114372253418\n",
      "[*] Test roc_auc: 0.7409120432166061\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 12 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7493315530555795 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 11...\n",
      "[*] Training Loss: 0.14188221096992493\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.11622629314661026\n",
      "mean sig(logit) neg = 0.024289719760417938\n",
      "mean logit pos = -2.8540396690368652\n",
      "mean logit neg = -4.355692386627197\n",
      "[*] Val Loss: 0.11842890083789825\n",
      "[*] Val roc_auc: 0.7673297679723384\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.08229724317789078\n",
      "mean sig(logit) neg = 0.016512908041477203\n",
      "mean logit pos = -3.4007954597473145\n",
      "mean logit neg = -4.756384372711182\n",
      "[*] Test Loss: 0.1409400999546051\n",
      "[*] Test roc_auc: 0.7495376456296481\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 11 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 12...\n",
      "[*] Training Loss: 0.142889603972435\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.11161649227142334\n",
      "mean sig(logit) neg = 0.025385910645127296\n",
      "mean logit pos = -2.815950632095337\n",
      "mean logit neg = -4.201013088226318\n",
      "[*] Val Loss: 0.11802931129932404\n",
      "[*] Val roc_auc: 0.7672786856267972\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07867272943258286\n",
      "mean sig(logit) neg = 0.01709897443652153\n",
      "mean logit pos = -3.4000439643859863\n",
      "mean logit neg = -4.690521240234375\n",
      "[*] Test Loss: 0.14124862849712372\n",
      "[*] Test roc_auc: 0.7416758811351052\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 10 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 13...\n",
      "[*] Training Loss: 0.14322735369205475\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.10072667896747589\n",
      "mean sig(logit) neg = 0.023132523521780968\n",
      "mean logit pos = -2.9247918128967285\n",
      "mean logit neg = -4.316355228424072\n",
      "[*] Val Loss: 0.11847282201051712\n",
      "[*] Val roc_auc: 0.7683601731269163\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.06727554649114609\n",
      "mean sig(logit) neg = 0.014620956964790821\n",
      "mean logit pos = -3.5535805225372314\n",
      "mean logit neg = -4.8129377365112305\n",
      "[*] Test Loss: 0.14355866611003876\n",
      "[*] Test roc_auc: 0.7458188569102302\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 9 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 14...\n",
      "[*] Training Loss: 0.14350992441177368\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.10206887125968933\n",
      "mean sig(logit) neg = 0.027125529944896698\n",
      "mean logit pos = -2.8663318157196045\n",
      "mean logit neg = -4.0450544357299805\n",
      "[*] Val Loss: 0.12076079100370407\n",
      "[*] Val roc_auc: 0.7511342814821295\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07854977995157242\n",
      "mean sig(logit) neg = 0.02022423967719078\n",
      "mean logit pos = -3.256364345550537\n",
      "mean logit neg = -4.344702243804932\n",
      "[*] Test Loss: 0.13922350108623505\n",
      "[*] Test roc_auc: 0.7394543498939681\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 8 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 15...\n",
      "[*] Training Loss: 0.14442910254001617\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09599662572145462\n",
      "mean sig(logit) neg = 0.027745870873332024\n",
      "mean logit pos = -2.851663827896118\n",
      "mean logit neg = -3.991572618484497\n",
      "[*] Val Loss: 0.12054222822189331\n",
      "[*] Val roc_auc: 0.7570196612346883\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07054557651281357\n",
      "mean sig(logit) neg = 0.01962253823876381\n",
      "mean logit pos = -3.3093526363372803\n",
      "mean logit neg = -4.3439555168151855\n",
      "[*] Test Loss: 0.1400395929813385\n",
      "[*] Test roc_auc: 0.7265047130195631\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 7 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 16...\n",
      "[*] Training Loss: 0.14441601932048798\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.11475110054016113\n",
      "mean sig(logit) neg = 0.033764101564884186\n",
      "mean logit pos = -2.604612350463867\n",
      "mean logit neg = -3.7113850116729736\n",
      "[*] Val Loss: 0.12000620365142822\n",
      "[*] Val roc_auc: 0.7604562449256648\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.10178305208683014\n",
      "mean sig(logit) neg = 0.03164137154817581\n",
      "mean logit pos = -2.7865653038024902\n",
      "mean logit neg = -3.760103464126587\n",
      "[*] Test Loss: 0.1354019194841385\n",
      "[*] Test roc_auc: 0.7363946906432629\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 6 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 17...\n",
      "[*] Training Loss: 0.14543433487415314\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1298300325870514\n",
      "mean sig(logit) neg = 0.04201064631342888\n",
      "mean logit pos = -2.4181320667266846\n",
      "mean logit neg = -3.4528143405914307\n",
      "[*] Val Loss: 0.12362740188837051\n",
      "[*] Val roc_auc: 0.7532353886041645\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.11849737912416458\n",
      "mean sig(logit) neg = 0.04001601040363312\n",
      "mean logit pos = -2.576796293258667\n",
      "mean logit neg = -3.478837728500366\n",
      "[*] Test Loss: 0.137529194355011\n",
      "[*] Test roc_auc: 0.7313239705344273\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 5 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 18...\n",
      "[*] Training Loss: 0.1456863433122635\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.12117666751146317\n",
      "mean sig(logit) neg = 0.03505808487534523\n",
      "mean logit pos = -2.625833034515381\n",
      "mean logit neg = -3.765570878982544\n",
      "[*] Val Loss: 0.12250898778438568\n",
      "[*] Val roc_auc: 0.7477203803087296\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.10527636855840683\n",
      "mean sig(logit) neg = 0.03100879304111004\n",
      "mean logit pos = -2.8530375957489014\n",
      "mean logit neg = -3.8808581829071045\n",
      "[*] Test Loss: 0.1374160349369049\n",
      "[*] Test roc_auc: 0.7269650696731803\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 4 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 19...\n",
      "[*] Training Loss: 0.14717452228069305\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09031205624341965\n",
      "mean sig(logit) neg = 0.04054689034819603\n",
      "mean logit pos = -2.6723110675811768\n",
      "mean logit neg = -3.436781644821167\n",
      "[*] Val Loss: 0.12766338884830475\n",
      "[*] Val roc_auc: 0.7383338014770222\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07077541202306747\n",
      "mean sig(logit) neg = 0.033089857548475266\n",
      "mean logit pos = -2.959637403488159\n",
      "mean logit neg = -3.655991554260254\n",
      "[*] Test Loss: 0.14124278724193573\n",
      "[*] Test roc_auc: 0.7220837658858279\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 3 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 20...\n",
      "[*] Training Loss: 0.14768929779529572\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.09959586709737778\n",
      "mean sig(logit) neg = 0.03793490305542946\n",
      "mean logit pos = -2.662313938140869\n",
      "mean logit neg = -3.6037940979003906\n",
      "[*] Val Loss: 0.125155508518219\n",
      "[*] Val roc_auc: 0.742487805368172\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.08128678053617477\n",
      "mean sig(logit) neg = 0.032537009567022324\n",
      "mean logit pos = -2.962338447570801\n",
      "mean logit neg = -3.782872200012207\n",
      "[*] Test Loss: 0.14133591949939728\n",
      "[*] Test roc_auc: 0.7225761718465901\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 2 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 21...\n",
      "[*] Training Loss: 0.15032850205898285\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.04438482224941254\n",
      "mean sig(logit) neg = 0.01028815284371376\n",
      "mean logit pos = -4.284101486206055\n",
      "mean logit neg = -5.761837482452393\n",
      "[*] Val Loss: 0.14517393708229065\n",
      "[*] Val roc_auc: 0.7199340917705674\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.028150534257292747\n",
      "mean sig(logit) neg = 0.0074707823805511\n",
      "mean logit pos = -4.936659336090088\n",
      "mean logit neg = -6.34534215927124\n",
      "[*] Test Loss: 0.18364132940769196\n",
      "[*] Test roc_auc: 0.7117225143986994\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 1 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 22...\n",
      "[*] Training Loss: 0.1509075164794922\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.06155312433838844\n",
      "mean sig(logit) neg = 0.014717038720846176\n",
      "mean logit pos = -3.577369451522827\n",
      "mean logit neg = -4.785819053649902\n",
      "[*] Val Loss: 0.12832418084144592\n",
      "[*] Val roc_auc: 0.7371819457118705\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.04819340631365776\n",
      "mean sig(logit) neg = 0.013936806470155716\n",
      "mean logit pos = -3.8622725009918213\n",
      "mean logit neg = -4.828790664672852\n",
      "[*] Test Loss: 0.1528698354959488\n",
      "[*] Test roc_auc: 0.7093690948351719\n",
      "\n",
      "[*] Best val loss: 0.11742711067199707 at epoch 2\n",
      "[*] Early stopping in 0 epochs\n",
      "[*] Best Val ROC AUC: 0.775517045365124 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7495376456296481 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Early stopping\n",
      "\n",
      "[*] ----------------------------- Iteration: 2 -----------------------------\n",
      "\n",
      "[*] Trial: <optuna.trial._trial.Trial object at 0x7800683bfc20>\n",
      "[*] HPT: {'memory': 5, 'seed': 43, 'num_layers': 6, 'state_size': 100, 'd_model_factor': 0.5, 'dropout': 0.09478585039640727, 'pos_weight': 8.138351544859589, 'batch_size': 50, 'n_accumulation_steps': 14, 'learning_rate': 0.00848668178979742, 'rec_learning_factor': 0.5, 'beta1': 0.8699875813644531, 'beta2': 0.9566257322215043, 'weight_decay': 0.00011624569787446802}\n",
      "[*] Npz file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists with matching meta. Using existing file.\n",
      "\n",
      "[*] -------------------- Dataset Statistics --------------------\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz\n",
      "[*] Number of nodes: 7047\n",
      "[*] Total number of edges used: 411700\n",
      "[*] Val_ratio: 0.2 | Test_ratio: 0.2\n",
      "[*] Number of features: 6\n",
      "[*] -----------------------------------------------------------\n",
      "\n",
      "[*] Trainable Parameters: 278501\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- decoder\n",
      "|  |  |  |- bias  shape=(1,)\n",
      "|  |  |  |- kernel  shape=(50, 1)\n",
      "|  |  |- encoder\n",
      "|  |     |- encoder\n",
      "|  |     |  |- bias  shape=(50,)\n",
      "|  |     |  |- kernel  shape=(6, 50)\n",
      "|  |     |- layers_0\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(200, 50)\n",
      "|  |     |     |- B_re  shape=(200, 50)\n",
      "|  |     |     |- C_im  shape=(50, 200)\n",
      "|  |     |     |- C_re  shape=(50, 200)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(200,)\n",
      "|  |     |     |- nu  shape=(400,)\n",
      "|  |     |     |- phi  shape=(100,)\n",
      "|  |     |     |- theta  shape=(400,)\n",
      "|  |     |- layers_1\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(200, 50)\n",
      "|  |     |     |- B_re  shape=(200, 50)\n",
      "|  |     |     |- C_im  shape=(50, 200)\n",
      "|  |     |     |- C_re  shape=(50, 200)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(200,)\n",
      "|  |     |     |- nu  shape=(400,)\n",
      "|  |     |     |- phi  shape=(100,)\n",
      "|  |     |     |- theta  shape=(400,)\n",
      "|  |     |- layers_2\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(200, 50)\n",
      "|  |     |     |- B_re  shape=(200, 50)\n",
      "|  |     |     |- C_im  shape=(50, 200)\n",
      "|  |     |     |- C_re  shape=(50, 200)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(200,)\n",
      "|  |     |     |- nu  shape=(400,)\n",
      "|  |     |     |- phi  shape=(100,)\n",
      "|  |     |     |- theta  shape=(400,)\n",
      "|  |     |- layers_3\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(200, 50)\n",
      "|  |     |     |- B_re  shape=(200, 50)\n",
      "|  |     |     |- C_im  shape=(50, 200)\n",
      "|  |     |     |- C_re  shape=(50, 200)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(200,)\n",
      "|  |     |     |- nu  shape=(400,)\n",
      "|  |     |     |- phi  shape=(100,)\n",
      "|  |     |     |- theta  shape=(400,)\n",
      "|  |     |- layers_4\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- scale  shape=(50,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(50,)\n",
      "|  |     |  |  |- kernel  shape=(50, 50)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(200, 50)\n",
      "|  |     |     |- B_re  shape=(200, 50)\n",
      "|  |     |     |- C_im  shape=(50, 200)\n",
      "|  |     |     |- C_re  shape=(50, 200)\n",
      "|  |     |     |- D  shape=(50,)\n",
      "|  |     |     |- gamma_log  shape=(200,)\n",
      "|  |     |     |- nu  shape=(400,)\n",
      "|  |     |     |- phi  shape=(100,)\n",
      "|  |     |     |- theta  shape=(400,)\n",
      "|  |     |- layers_5\n",
      "|  |        |- norm\n",
      "|  |        |  |- bias  shape=(50,)\n",
      "|  |        |  |- scale  shape=(50,)\n",
      "|  |        |- out1\n",
      "|  |        |  |- bias  shape=(50,)\n",
      "|  |        |  |- kernel  shape=(50, 50)\n",
      "|  |        |- out2\n",
      "|  |        |  |- bias  shape=(50,)\n",
      "|  |        |  |- kernel  shape=(50, 50)\n",
      "|  |        |- seq\n",
      "|  |           |- B_im  shape=(200, 50)\n",
      "|  |           |- B_re  shape=(200, 50)\n",
      "|  |           |- C_im  shape=(50, 200)\n",
      "|  |           |- C_re  shape=(50, 200)\n",
      "|  |           |- D  shape=(50,)\n",
      "|  |           |- gamma_log  shape=(200,)\n",
      "|  |           |- nu  shape=(400,)\n",
      "|  |           |- phi  shape=(100,)\n",
      "|  |           |- theta  shape=(400,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 200)\n",
      "|        |- layers_1\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 200)\n",
      "|        |- layers_2\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 200)\n",
      "|        |- layers_3\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 200)\n",
      "|        |- layers_4\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 200)\n",
      "|        |- layers_5\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(50, 200)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py:5518: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "[*] Training Loss: 0.33192554116249084\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.29605549573898315\n",
      "mean sig(logit) neg = 0.10872158408164978\n",
      "mean logit pos = -1.201656699180603\n",
      "mean logit neg = -2.3839197158813477\n",
      "[*] Val Loss: 0.23709172010421753\n",
      "[*] Val roc_auc: 0.7462125198947321\n",
      "\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.2873792052268982\n",
      "mean sig(logit) neg = 0.1107712835073471\n",
      "mean logit pos = -1.2434836626052856\n",
      "mean logit neg = -2.3515610694885254\n",
      "[*] Test Loss: 0.25687581300735474\n",
      "[*] Test roc_auc: 0.7370911480856365\n",
      "\n",
      "[*] Best val loss: 0.23709172010421753 at epoch 1\n",
      "[*] Best Val ROC AUC: 0.7462125198947321 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.7370911480856365 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 2...\n",
      "[*] Training Loss: 0.26323577761650085\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.24915483593940735\n",
      "mean sig(logit) neg = 0.08478393405675888\n",
      "mean logit pos = -1.4922800064086914\n",
      "mean logit neg = -2.6908674240112305\n",
      "[*] Val Loss: 0.21873725950717926\n",
      "[*] Val roc_auc: 0.7617481465093032\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.22592930495738983\n",
      "mean sig(logit) neg = 0.080579973757267\n",
      "mean logit pos = -1.6644561290740967\n",
      "mean logit neg = -2.7394495010375977\n",
      "[*] Test Loss: 0.24085915088653564\n",
      "[*] Test roc_auc: 0.740028728114551\n",
      "\n",
      "[*] Best val loss: 0.21873725950717926 at epoch 2\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 3...\n",
      "[*] Training Loss: 0.26143813133239746\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.15384292602539062\n",
      "mean sig(logit) neg = 0.05199668928980827\n",
      "mean logit pos = -2.1860032081604004\n",
      "mean logit neg = -3.1611406803131104\n",
      "[*] Val Loss: 0.21690918505191803\n",
      "[*] Val roc_auc: 0.7325874273427022\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.1390092521905899\n",
      "mean sig(logit) neg = 0.04842760041356087\n",
      "mean logit pos = -2.326815128326416\n",
      "mean logit neg = -3.2243967056274414\n",
      "[*] Test Loss: 0.2445726841688156\n",
      "[*] Test roc_auc: 0.7242846990643305\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 4...\n",
      "[*] Training Loss: 0.2665526866912842\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.1318037360906601\n",
      "mean sig(logit) neg = 0.043776143342256546\n",
      "mean logit pos = -2.413513660430908\n",
      "mean logit neg = -3.402883529663086\n",
      "[*] Val Loss: 0.2214897871017456\n",
      "[*] Val roc_auc: 0.7267872313385964\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.12087289243936539\n",
      "mean sig(logit) neg = 0.0414813794195652\n",
      "mean logit pos = -2.5540120601654053\n",
      "mean logit neg = -3.439474105834961\n",
      "[*] Test Loss: 0.2530251443386078\n",
      "[*] Test roc_auc: 0.6954383575244281\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 5...\n",
      "[*] Training Loss: 0.2683812379837036\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.08100871741771698\n",
      "mean sig(logit) neg = 0.021729210391640663\n",
      "mean logit pos = -3.196727752685547\n",
      "mean logit neg = -4.604510307312012\n",
      "[*] Val Loss: 0.24680884182453156\n",
      "[*] Val roc_auc: 0.7426757603346761\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.06978942453861237\n",
      "mean sig(logit) neg = 0.02055269479751587\n",
      "mean logit pos = -3.5027260780334473\n",
      "mean logit neg = -4.6111931800842285\n",
      "[*] Test Loss: 0.299456387758255\n",
      "[*] Test roc_auc: 0.7026782533581785\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 6...\n",
      "[*] Training Loss: 0.27162590622901917\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.040775783360004425\n",
      "mean sig(logit) neg = 0.020545734092593193\n",
      "mean logit pos = -3.554145097732544\n",
      "mean logit neg = -4.250668048858643\n",
      "[*] Val Loss: 0.26642799377441406\n",
      "[*] Val roc_auc: 0.7060481509983392\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.03627275675535202\n",
      "mean sig(logit) neg = 0.019641557708382607\n",
      "mean logit pos = -3.7373621463775635\n",
      "mean logit neg = -4.30078649520874\n",
      "[*] Test Loss: 0.31356915831565857\n",
      "[*] Test roc_auc: 0.6643316044421255\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 7...\n",
      "[*] Training Loss: 0.2734712064266205\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.1337118148803711\n",
      "mean sig(logit) neg = 0.03616674244403839\n",
      "mean logit pos = -2.552220344543457\n",
      "mean logit neg = -3.9415082931518555\n",
      "[*] Val Loss: 0.22324791550636292\n",
      "[*] Val roc_auc: 0.7463561052457586\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.11230363696813583\n",
      "mean sig(logit) neg = 0.03211065009236336\n",
      "mean logit pos = -2.9255404472351074\n",
      "mean logit neg = -4.05844259262085\n",
      "[*] Test Loss: 0.2713315486907959\n",
      "[*] Test roc_auc: 0.7070871276825464\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 16 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 8...\n",
      "[*] Training Loss: 0.2794543206691742\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.11720219254493713\n",
      "mean sig(logit) neg = 0.037543199956417084\n",
      "mean logit pos = -2.5553598403930664\n",
      "mean logit neg = -3.5733776092529297\n",
      "[*] Val Loss: 0.22278480231761932\n",
      "[*] Val roc_auc: 0.7435520793478665\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.10140010714530945\n",
      "mean sig(logit) neg = 0.03419214114546776\n",
      "mean logit pos = -2.8150932788848877\n",
      "mean logit neg = -3.6627914905548096\n",
      "[*] Test Loss: 0.26313596963882446\n",
      "[*] Test roc_auc: 0.7067532521107116\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 15 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 9...\n",
      "[*] Training Loss: 0.2976110279560089\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.20529566705226898\n",
      "mean sig(logit) neg = 0.08545868843793869\n",
      "mean logit pos = -1.937279462814331\n",
      "mean logit neg = -2.9617204666137695\n",
      "[*] Val Loss: 0.243439719080925\n",
      "[*] Val roc_auc: 0.6703861983392906\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.1991797536611557\n",
      "mean sig(logit) neg = 0.08238367736339569\n",
      "mean logit pos = -2.139864921569824\n",
      "mean logit neg = -3.015190601348877\n",
      "[*] Test Loss: 0.27533581852912903\n",
      "[*] Test roc_auc: 0.6637732004108237\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 14 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 10...\n",
      "[*] Training Loss: 0.2906422019004822\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.08575168997049332\n",
      "mean sig(logit) neg = 0.03680729120969772\n",
      "mean logit pos = -2.90138840675354\n",
      "mean logit neg = -3.8548943996429443\n",
      "[*] Val Loss: 0.24279844760894775\n",
      "[*] Val roc_auc: 0.6988639300891397\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.0761253833770752\n",
      "mean sig(logit) neg = 0.03384324908256531\n",
      "mean logit pos = -3.212007522583008\n",
      "mean logit neg = -3.975295305252075\n",
      "[*] Test Loss: 0.2911663353443146\n",
      "[*] Test roc_auc: 0.6737046257972474\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 13 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 11...\n",
      "[*] Training Loss: 0.28601163625717163\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.21174326539039612\n",
      "mean sig(logit) neg = 0.08487158268690109\n",
      "mean logit pos = -1.7661426067352295\n",
      "mean logit neg = -2.812619924545288\n",
      "[*] Val Loss: 0.23115524649620056\n",
      "[*] Val roc_auc: 0.7197173807160975\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.1907099187374115\n",
      "mean sig(logit) neg = 0.07430069893598557\n",
      "mean logit pos = -1.9997678995132446\n",
      "mean logit neg = -2.960906744003296\n",
      "[*] Test Loss: 0.2537809908390045\n",
      "[*] Test roc_auc: 0.7012848682960846\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 12 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 12...\n",
      "[*] Training Loss: 0.28211185336112976\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.2087647020816803\n",
      "mean sig(logit) neg = 0.08067186921834946\n",
      "mean logit pos = -1.8162201642990112\n",
      "mean logit neg = -2.814613103866577\n",
      "[*] Val Loss: 0.22985057532787323\n",
      "[*] Val roc_auc: 0.7106287930736781\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.19543854892253876\n",
      "mean sig(logit) neg = 0.0741940513253212\n",
      "mean logit pos = -1.9625530242919922\n",
      "mean logit neg = -2.9176278114318848\n",
      "[*] Test Loss: 0.25179868936538696\n",
      "[*] Test roc_auc: 0.6981074848620303\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 11 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 13...\n",
      "[*] Training Loss: 0.2873111665248871\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.15086157619953156\n",
      "mean sig(logit) neg = 0.059032242745161057\n",
      "mean logit pos = -2.180194139480591\n",
      "mean logit neg = -3.140099048614502\n",
      "[*] Val Loss: 0.22298742830753326\n",
      "[*] Val roc_auc: 0.7315839337455862\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.1395496428012848\n",
      "mean sig(logit) neg = 0.05595540627837181\n",
      "mean logit pos = -2.360712766647339\n",
      "mean logit neg = -3.20194149017334\n",
      "[*] Test Loss: 0.2547352910041809\n",
      "[*] Test roc_auc: 0.7097338372263465\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 10 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 14...\n",
      "[*] Training Loss: 0.2819948196411133\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.14609076082706451\n",
      "mean sig(logit) neg = 0.05403921380639076\n",
      "mean logit pos = -3.6662092208862305\n",
      "mean logit neg = -4.800108432769775\n",
      "[*] Val Loss: 0.3203345835208893\n",
      "[*] Val roc_auc: 0.6678018037985042\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.13835744559764862\n",
      "mean sig(logit) neg = 0.04793747141957283\n",
      "mean logit pos = -3.468376398086548\n",
      "mean logit neg = -4.833498954772949\n",
      "[*] Test Loss: 0.3336677849292755\n",
      "[*] Test roc_auc: 0.6730050161488346\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 9 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 15...\n",
      "[*] Training Loss: 0.28909987211227417\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.10996285825967789\n",
      "mean sig(logit) neg = 0.06243837624788284\n",
      "mean logit pos = -2.3649532794952393\n",
      "mean logit neg = -2.9402880668640137\n",
      "[*] Val Loss: 0.23466216027736664\n",
      "[*] Val roc_auc: 0.6680197692678045\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.10719909518957138\n",
      "mean sig(logit) neg = 0.06079601123929024\n",
      "mean logit pos = -2.4661216735839844\n",
      "mean logit neg = -2.9667258262634277\n",
      "[*] Test Loss: 0.263989120721817\n",
      "[*] Test roc_auc: 0.6671470550099478\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 8 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 16...\n",
      "[*] Training Loss: 0.28605106472969055\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.14605531096458435\n",
      "mean sig(logit) neg = 0.06594319641590118\n",
      "mean logit pos = -2.48412823677063\n",
      "mean logit neg = -3.2227766513824463\n",
      "[*] Val Loss: 0.25130587816238403\n",
      "[*] Val roc_auc: 0.664831135953476\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.14368925988674164\n",
      "mean sig(logit) neg = 0.06346585601568222\n",
      "mean logit pos = -2.5028204917907715\n",
      "mean logit neg = -3.2722747325897217\n",
      "[*] Test Loss: 0.27493998408317566\n",
      "[*] Test roc_auc: 0.6628529180388477\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 7 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 17...\n",
      "[*] Training Loss: 0.288846880197525\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.13948586583137512\n",
      "mean sig(logit) neg = 0.06460551172494888\n",
      "mean logit pos = -2.27174711227417\n",
      "mean logit neg = -3.006770372390747\n",
      "[*] Val Loss: 0.23441164195537567\n",
      "[*] Val roc_auc: 0.6690740724429743\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.13644342124462128\n",
      "mean sig(logit) neg = 0.062043920159339905\n",
      "mean logit pos = -2.3392324447631836\n",
      "mean logit neg = -3.061535358428955\n",
      "[*] Test Loss: 0.25956642627716064\n",
      "[*] Test roc_auc: 0.6634922379985779\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 6 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 18...\n",
      "[*] Training Loss: 0.2955302894115448\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.14433345198631287\n",
      "mean sig(logit) neg = 0.06464862823486328\n",
      "mean logit pos = -2.3606014251708984\n",
      "mean logit neg = -3.09867787361145\n",
      "[*] Val Loss: 0.2413463145494461\n",
      "[*] Val roc_auc: 0.6711535434789362\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.14330774545669556\n",
      "mean sig(logit) neg = 0.062264829874038696\n",
      "mean logit pos = -2.3055195808410645\n",
      "mean logit neg = -3.1384146213531494\n",
      "[*] Test Loss: 0.2582370638847351\n",
      "[*] Test roc_auc: 0.6743617522464257\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 5 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 19...\n",
      "[*] Training Loss: 0.2866094708442688\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.1569051593542099\n",
      "mean sig(logit) neg = 0.07082387804985046\n",
      "mean logit pos = -2.1444876194000244\n",
      "mean logit neg = -2.8869521617889404\n",
      "[*] Val Loss: 0.23489297926425934\n",
      "[*] Val roc_auc: 0.6705498452328201\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.15638956427574158\n",
      "mean sig(logit) neg = 0.06815527379512787\n",
      "mean logit pos = -2.167294502258301\n",
      "mean logit neg = -2.937839984893799\n",
      "[*] Test Loss: 0.2557564675807953\n",
      "[*] Test roc_auc: 0.6720462698902032\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 4 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 20...\n",
      "[*] Training Loss: 0.2879463732242584\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.15467345714569092\n",
      "mean sig(logit) neg = 0.07021747529506683\n",
      "mean logit pos = -2.232874870300293\n",
      "mean logit neg = -3.238497257232666\n",
      "[*] Val Loss: 0.23982635140419006\n",
      "[*] Val roc_auc: 0.6719447515752786\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.15301571786403656\n",
      "mean sig(logit) neg = 0.06762677431106567\n",
      "mean logit pos = -2.417574167251587\n",
      "mean logit neg = -3.2314231395721436\n",
      "[*] Test Loss: 0.27400174736976624\n",
      "[*] Test roc_auc: 0.6714801621764583\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 3 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 21...\n",
      "[*] Training Loss: 0.2877205014228821\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.12340909987688065\n",
      "mean sig(logit) neg = 0.06312565505504608\n",
      "mean logit pos = -2.45133638381958\n",
      "mean logit neg = -3.036663293838501\n",
      "[*] Val Loss: 0.2428661435842514\n",
      "[*] Val roc_auc: 0.6715465600843463\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.12354966998100281\n",
      "mean sig(logit) neg = 0.06141408905386925\n",
      "mean logit pos = -2.3416733741760254\n",
      "mean logit neg = -3.0586400032043457\n",
      "[*] Test Loss: 0.25701743364334106\n",
      "[*] Test roc_auc: 0.6773495658932103\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 2 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 22...\n",
      "[*] Training Loss: 0.2832716107368469\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.1370033472776413\n",
      "mean sig(logit) neg = 0.06343026459217072\n",
      "mean logit pos = -2.3835177421569824\n",
      "mean logit neg = -3.1602120399475098\n",
      "[*] Val Loss: 0.2405773401260376\n",
      "[*] Val roc_auc: 0.6687315021102989\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.13616232573986053\n",
      "mean sig(logit) neg = 0.06112801656126976\n",
      "mean logit pos = -2.3639585971832275\n",
      "mean logit neg = -3.171314001083374\n",
      "[*] Test Loss: 0.2604602873325348\n",
      "[*] Test roc_auc: 0.6729640129290381\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 1 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 23...\n",
      "[*] Training Loss: 0.2832905054092407\n",
      "prevalence = 0.008391013368964195\n",
      "mean sig(logit) pos = 0.14571096003055573\n",
      "mean sig(logit) neg = 0.06383033096790314\n",
      "mean logit pos = -2.262972593307495\n",
      "mean logit neg = -3.1251161098480225\n",
      "[*] Val Loss: 0.23400869965553284\n",
      "[*] Val roc_auc: 0.6738677532130413\n",
      "\n",
      "prevalence = 0.009556769393384457\n",
      "mean sig(logit) pos = 0.14320826530456543\n",
      "mean sig(logit) neg = 0.06145947799086571\n",
      "mean logit pos = -2.348745822906494\n",
      "mean logit neg = -3.1783814430236816\n",
      "[*] Test Loss: 0.26087188720703125\n",
      "[*] Test roc_auc: 0.6738168783429328\n",
      "\n",
      "[*] Best val loss: 0.21690918505191803 at epoch 3\n",
      "[*] Early stopping in 0 epochs\n",
      "[*] Best Val ROC AUC: 0.7617481465093032 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.740028728114551 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Early stopping\n",
      "\n",
      "[*] ----------------------------- Iteration: 3 -----------------------------\n",
      "\n",
      "[*] Trial: <optuna.trial._trial.Trial object at 0x78016c47dd00>\n",
      "[*] HPT: {'memory': 5, 'seed': 43, 'num_layers': 6, 'state_size': 32, 'd_model_factor': 1.0, 'dropout': 0.27891717009522565, 'pos_weight': 7.11561487699408, 'batch_size': 128, 'n_accumulation_steps': 8, 'learning_rate': 0.002097356684185756, 'rec_learning_factor': 0.5, 'beta1': 0.920514533134913, 'beta2': 0.9771672878162749, 'weight_decay': 0.32092074838004997}\n",
      "[*] Npz file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists with matching meta. Using existing file.\n",
      "\n",
      "[*] -------------------- Dataset Statistics --------------------\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz\n",
      "[*] Number of nodes: 7047\n",
      "[*] Total number of edges used: 411648\n",
      "[*] Val_ratio: 0.2 | Test_ratio: 0.2\n",
      "[*] Number of features: 6\n",
      "[*] -----------------------------------------------------------\n",
      "\n",
      "[*] Trainable Parameters: 64769\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- decoder\n",
      "|  |  |  |- bias  shape=(1,)\n",
      "|  |  |  |- kernel  shape=(32, 1)\n",
      "|  |  |- encoder\n",
      "|  |     |- encoder\n",
      "|  |     |  |- bias  shape=(32,)\n",
      "|  |     |  |- kernel  shape=(6, 32)\n",
      "|  |     |- layers_0\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_1\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_2\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_3\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_4\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- scale  shape=(32,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(32,)\n",
      "|  |     |  |  |- kernel  shape=(32, 32)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(64, 32)\n",
      "|  |     |     |- B_re  shape=(64, 32)\n",
      "|  |     |     |- C_im  shape=(32, 64)\n",
      "|  |     |     |- C_re  shape=(32, 64)\n",
      "|  |     |     |- D  shape=(32,)\n",
      "|  |     |     |- gamma_log  shape=(64,)\n",
      "|  |     |     |- nu  shape=(128,)\n",
      "|  |     |     |- phi  shape=(32,)\n",
      "|  |     |     |- theta  shape=(128,)\n",
      "|  |     |- layers_5\n",
      "|  |        |- norm\n",
      "|  |        |  |- bias  shape=(32,)\n",
      "|  |        |  |- scale  shape=(32,)\n",
      "|  |        |- out1\n",
      "|  |        |  |- bias  shape=(32,)\n",
      "|  |        |  |- kernel  shape=(32, 32)\n",
      "|  |        |- out2\n",
      "|  |        |  |- bias  shape=(32,)\n",
      "|  |        |  |- kernel  shape=(32, 32)\n",
      "|  |        |- seq\n",
      "|  |           |- B_im  shape=(64, 32)\n",
      "|  |           |- B_re  shape=(64, 32)\n",
      "|  |           |- C_im  shape=(32, 64)\n",
      "|  |           |- C_re  shape=(32, 64)\n",
      "|  |           |- D  shape=(32,)\n",
      "|  |           |- gamma_log  shape=(64,)\n",
      "|  |           |- nu  shape=(128,)\n",
      "|  |           |- phi  shape=(32,)\n",
      "|  |           |- theta  shape=(128,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 64)\n",
      "|        |- layers_1\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 64)\n",
      "|        |- layers_2\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 64)\n",
      "|        |- layers_3\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 64)\n",
      "|        |- layers_4\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(128, 64)\n",
      "|        |- layers_5\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(128, 64)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py:5518: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "[*] Training Loss: 0.4973381459712982\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.10862606763839722\n",
      "mean sig(logit) neg = 0.04166502505540848\n",
      "mean logit pos = -2.674999952316284\n",
      "mean logit neg = -3.5997350215911865\n",
      "[*] Val Loss: 0.21354222297668457\n",
      "[*] Val roc_auc: 0.7079408461992823\n",
      "\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07849206775426865\n",
      "mean sig(logit) neg = 0.03304477035999298\n",
      "mean logit pos = -3.169887065887451\n",
      "mean logit neg = -3.866218090057373\n",
      "[*] Test Loss: 0.25977203249931335\n",
      "[*] Test roc_auc: 0.6548281660829276\n",
      "\n",
      "[*] Best val loss: 0.21354222297668457 at epoch 1\n",
      "[*] Best Val ROC AUC: 0.7079408461992823 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6548281660829276 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 2...\n",
      "[*] Training Loss: 0.26129046082496643\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1114034578204155\n",
      "mean sig(logit) neg = 0.032762981951236725\n",
      "mean logit pos = -2.6903884410858154\n",
      "mean logit neg = -3.7250540256500244\n",
      "[*] Val Loss: 0.20270943641662598\n",
      "[*] Val roc_auc: 0.7315890913006455\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.0722009688615799\n",
      "mean sig(logit) neg = 0.021713966503739357\n",
      "mean logit pos = -3.2810170650482178\n",
      "mean logit neg = -4.143263339996338\n",
      "[*] Test Loss: 0.2515338063240051\n",
      "[*] Test roc_auc: 0.6984605938200508\n",
      "\n",
      "[*] Best val loss: 0.20270943641662598 at epoch 2\n",
      "[*] Best Val ROC AUC: 0.7315890913006455 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.6984605938200508 at epoch 2\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 3...\n",
      "[*] Training Loss: 0.24015462398529053\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.12716694176197052\n",
      "mean sig(logit) neg = 0.03789491578936577\n",
      "mean logit pos = -2.5259265899658203\n",
      "mean logit neg = -3.5724575519561768\n",
      "[*] Val Loss: 0.19917204976081848\n",
      "[*] Val roc_auc: 0.7305526843039023\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.09060916304588318\n",
      "mean sig(logit) neg = 0.023216698318719864\n",
      "mean logit pos = -3.074956178665161\n",
      "mean logit neg = -4.134976863861084\n",
      "[*] Test Loss: 0.24021002650260925\n",
      "[*] Test roc_auc: 0.7325423514387025\n",
      "\n",
      "[*] Best val loss: 0.19917204976081848 at epoch 3\n",
      "[*] Best Val ROC AUC: 0.7315890913006455 at epoch 2\n",
      "[*] Best Test ROC AUC: 0.7325423514387025 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 4...\n",
      "[*] Training Loss: 0.23556022346019745\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.14169584214687347\n",
      "mean sig(logit) neg = 0.04245736449956894\n",
      "mean logit pos = -2.3887901306152344\n",
      "mean logit neg = -3.446457624435425\n",
      "[*] Val Loss: 0.197352334856987\n",
      "[*] Val roc_auc: 0.7327332558162074\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.12380241602659225\n",
      "mean sig(logit) neg = 0.03554827347397804\n",
      "mean logit pos = -2.6130974292755127\n",
      "mean logit neg = -3.6450002193450928\n",
      "[*] Test Loss: 0.2249184250831604\n",
      "[*] Test roc_auc: 0.7313737339704302\n",
      "\n",
      "[*] Best val loss: 0.197352334856987 at epoch 4\n",
      "[*] Best Val ROC AUC: 0.7327332558162074 at epoch 4\n",
      "[*] Best Test ROC AUC: 0.7325423514387025 at epoch 3\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 5...\n",
      "[*] Training Loss: 0.23368790745735168\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.12378884106874466\n",
      "mean sig(logit) neg = 0.03787710890173912\n",
      "mean logit pos = -2.5505008697509766\n",
      "mean logit neg = -3.5496132373809814\n",
      "[*] Val Loss: 0.20048119127750397\n",
      "[*] Val roc_auc: 0.7295063898279179\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.07395239174365997\n",
      "mean sig(logit) neg = 0.01934322528541088\n",
      "mean logit pos = -3.2646989822387695\n",
      "mean logit neg = -4.352144718170166\n",
      "[*] Test Loss: 0.24734269082546234\n",
      "[*] Test roc_auc: 0.7418619887382465\n",
      "\n",
      "[*] Best val loss: 0.197352334856987 at epoch 4\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7327332558162074 at epoch 4\n",
      "[*] Best Test ROC AUC: 0.7418619887382465 at epoch 5\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 6...\n",
      "[*] Training Loss: 0.23146319389343262\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16014249622821808\n",
      "mean sig(logit) neg = 0.05027414858341217\n",
      "mean logit pos = -2.19010329246521\n",
      "mean logit neg = -3.2177131175994873\n",
      "[*] Val Loss: 0.19613972306251526\n",
      "[*] Val roc_auc: 0.7415795088039022\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.11646907776594162\n",
      "mean sig(logit) neg = 0.03219980001449585\n",
      "mean logit pos = -2.645176649093628\n",
      "mean logit neg = -3.6991729736328125\n",
      "[*] Test Loss: 0.2226366102695465\n",
      "[*] Test roc_auc: 0.7514215549390518\n",
      "\n",
      "[*] Best val loss: 0.19613972306251526 at epoch 6\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7514215549390518 at epoch 6\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 7...\n",
      "[*] Training Loss: 0.22923649847507477\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.187043696641922\n",
      "mean sig(logit) neg = 0.060377828776836395\n",
      "mean logit pos = -1.966819405555725\n",
      "mean logit neg = -2.98370623588562\n",
      "[*] Val Loss: 0.19673696160316467\n",
      "[*] Val roc_auc: 0.7389806222300943\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.17719270288944244\n",
      "mean sig(logit) neg = 0.056268610060214996\n",
      "mean logit pos = -2.047497272491455\n",
      "mean logit neg = -3.046410322189331\n",
      "[*] Test Loss: 0.21461887657642365\n",
      "[*] Test roc_auc: 0.7380352764936724\n",
      "\n",
      "[*] Best val loss: 0.19613972306251526 at epoch 6\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7514215549390518 at epoch 6\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 8...\n",
      "[*] Training Loss: 0.22669194638729095\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.18540379405021667\n",
      "mean sig(logit) neg = 0.0615551695227623\n",
      "mean logit pos = -1.9557814598083496\n",
      "mean logit neg = -2.956768035888672\n",
      "[*] Val Loss: 0.19689956307411194\n",
      "[*] Val roc_auc: 0.7391703071173756\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1730005145072937\n",
      "mean sig(logit) neg = 0.05542296916246414\n",
      "mean logit pos = -2.061292886734009\n",
      "mean logit neg = -3.0622236728668213\n",
      "[*] Test Loss: 0.21394146978855133\n",
      "[*] Test roc_auc: 0.7443524157732971\n",
      "\n",
      "[*] Best val loss: 0.19613972306251526 at epoch 6\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7514215549390518 at epoch 6\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 9...\n",
      "[*] Training Loss: 0.22499707341194153\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.19062377512454987\n",
      "mean sig(logit) neg = 0.06159282475709915\n",
      "mean logit pos = -1.9398255348205566\n",
      "mean logit neg = -2.9730825424194336\n",
      "[*] Val Loss: 0.19678635895252228\n",
      "[*] Val roc_auc: 0.7387273267074773\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.18564555048942566\n",
      "mean sig(logit) neg = 0.059827059507369995\n",
      "mean logit pos = -1.967166543006897\n",
      "mean logit neg = -2.9837632179260254\n",
      "[*] Test Loss: 0.21403245627880096\n",
      "[*] Test roc_auc: 0.7461992970908812\n",
      "\n",
      "[*] Best val loss: 0.19613972306251526 at epoch 6\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7514215549390518 at epoch 6\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 10...\n",
      "[*] Training Loss: 0.22404418885707855\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1926538348197937\n",
      "mean sig(logit) neg = 0.06127563491463661\n",
      "mean logit pos = -1.930612325668335\n",
      "mean logit neg = -2.981996774673462\n",
      "[*] Val Loss: 0.19616901874542236\n",
      "[*] Val roc_auc: 0.7427039783855435\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1875465363264084\n",
      "mean sig(logit) neg = 0.059754811227321625\n",
      "mean logit pos = -1.9569507837295532\n",
      "mean logit neg = -2.9890494346618652\n",
      "[*] Test Loss: 0.2136051505804062\n",
      "[*] Test roc_auc: 0.7489822803774212\n",
      "\n",
      "[*] Best val loss: 0.19613972306251526 at epoch 6\n",
      "[*] Early stopping in 16 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7514215549390518 at epoch 6\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 11...\n",
      "[*] Training Loss: 0.22366078197956085\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.172623872756958\n",
      "mean sig(logit) neg = 0.05773909389972687\n",
      "mean logit pos = -2.0392308235168457\n",
      "mean logit neg = -3.015897750854492\n",
      "[*] Val Loss: 0.195806622505188\n",
      "[*] Val roc_auc: 0.7414232386171506\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16184896230697632\n",
      "mean sig(logit) neg = 0.054042164236307144\n",
      "mean logit pos = -2.103137969970703\n",
      "mean logit neg = -3.0683858394622803\n",
      "[*] Test Loss: 0.21343135833740234\n",
      "[*] Test roc_auc: 0.7531817072574614\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 12...\n",
      "[*] Training Loss: 0.2232198566198349\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17057539522647858\n",
      "mean sig(logit) neg = 0.057466380298137665\n",
      "mean logit pos = -2.0591280460357666\n",
      "mean logit neg = -3.0256242752075195\n",
      "[*] Val Loss: 0.19653242826461792\n",
      "[*] Val roc_auc: 0.7373212862579066\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16169153153896332\n",
      "mean sig(logit) neg = 0.05405304208397865\n",
      "mean logit pos = -2.113898515701294\n",
      "mean logit neg = -3.07173228263855\n",
      "[*] Test Loss: 0.21424409747123718\n",
      "[*] Test roc_auc: 0.7478937744716397\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 13...\n",
      "[*] Training Loss: 0.22241707146167755\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16521622240543365\n",
      "mean sig(logit) neg = 0.055399954319000244\n",
      "mean logit pos = -2.119593381881714\n",
      "mean logit neg = -3.0665314197540283\n",
      "[*] Val Loss: 0.19744469225406647\n",
      "[*] Val roc_auc: 0.7259699354833088\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.15902811288833618\n",
      "mean sig(logit) neg = 0.05395157262682915\n",
      "mean logit pos = -2.1416587829589844\n",
      "mean logit neg = -3.068342447280884\n",
      "[*] Test Loss: 0.2157452255487442\n",
      "[*] Test roc_auc: 0.7370111735418401\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 14...\n",
      "[*] Training Loss: 0.22195741534233093\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1711614727973938\n",
      "mean sig(logit) neg = 0.0602746307849884\n",
      "mean logit pos = -2.0455567836761475\n",
      "mean logit neg = -2.9713127613067627\n",
      "[*] Val Loss: 0.19908630847930908\n",
      "[*] Val roc_auc: 0.7286010452808316\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1707519292831421\n",
      "mean sig(logit) neg = 0.059588268399238586\n",
      "mean logit pos = -2.039947032928467\n",
      "mean logit neg = -2.9651613235473633\n",
      "[*] Test Loss: 0.21654720604419708\n",
      "[*] Test roc_auc: 0.7349016783130431\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 15...\n",
      "[*] Training Loss: 0.22084861993789673\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16970056295394897\n",
      "mean sig(logit) neg = 0.057948559522628784\n",
      "mean logit pos = -2.0577292442321777\n",
      "mean logit neg = -3.0156636238098145\n",
      "[*] Val Loss: 0.19686533510684967\n",
      "[*] Val roc_auc: 0.7370898907904799\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16699133813381195\n",
      "mean sig(logit) neg = 0.05728201940655708\n",
      "mean logit pos = -2.065812587738037\n",
      "mean logit neg = -3.0085766315460205\n",
      "[*] Test Loss: 0.21511803567409515\n",
      "[*] Test roc_auc: 0.7402145357365616\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 16 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 16...\n",
      "[*] Training Loss: 0.22077858448028564\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17883901298046112\n",
      "mean sig(logit) neg = 0.06367810815572739\n",
      "mean logit pos = -1.989379644393921\n",
      "mean logit neg = -2.942411422729492\n",
      "[*] Val Loss: 0.20049342513084412\n",
      "[*] Val roc_auc: 0.7300414429424427\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.17940720915794373\n",
      "mean sig(logit) neg = 0.062242522835731506\n",
      "mean logit pos = -1.9793521165847778\n",
      "mean logit neg = -2.949631929397583\n",
      "[*] Test Loss: 0.21648937463760376\n",
      "[*] Test roc_auc: 0.7366748860224568\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 15 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 17...\n",
      "[*] Training Loss: 0.22041109204292297\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17493556439876556\n",
      "mean sig(logit) neg = 0.06411725282669067\n",
      "mean logit pos = -2.0077455043792725\n",
      "mean logit neg = -2.9232139587402344\n",
      "[*] Val Loss: 0.20184488594532013\n",
      "[*] Val roc_auc: 0.7271860598635296\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1782001405954361\n",
      "mean sig(logit) neg = 0.0623210109770298\n",
      "mean logit pos = -1.9798091650009155\n",
      "mean logit neg = -2.9421801567077637\n",
      "[*] Test Loss: 0.21679429709911346\n",
      "[*] Test roc_auc: 0.7414860122059244\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 14 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 18...\n",
      "[*] Training Loss: 0.2212674766778946\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.18235169351100922\n",
      "mean sig(logit) neg = 0.06322814524173737\n",
      "mean logit pos = -1.963093638420105\n",
      "mean logit neg = -2.9364850521087646\n",
      "[*] Val Loss: 0.198692187666893\n",
      "[*] Val roc_auc: 0.733490421548943\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1790664941072464\n",
      "mean sig(logit) neg = 0.06376255303621292\n",
      "mean logit pos = -1.9720557928085327\n",
      "mean logit neg = -2.902470827102661\n",
      "[*] Test Loss: 0.21753190457820892\n",
      "[*] Test roc_auc: 0.7322905688979103\n",
      "\n",
      "[*] Best val loss: 0.195806622505188 at epoch 11\n",
      "[*] Early stopping in 13 epochs\n",
      "[*] Best Val ROC AUC: 0.7415795088039022 at epoch 6\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 19...\n",
      "[*] Training Loss: 0.2211022973060608\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17946791648864746\n",
      "mean sig(logit) neg = 0.059678949415683746\n",
      "mean logit pos = -1.9828941822052002\n",
      "mean logit neg = -3.003145217895508\n",
      "[*] Val Loss: 0.19529646635055542\n",
      "[*] Val roc_auc: 0.7491133056217165\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1698133945465088\n",
      "mean sig(logit) neg = 0.058381982147693634\n",
      "mean logit pos = -2.0435774326324463\n",
      "mean logit neg = -3.0014326572418213\n",
      "[*] Test Loss: 0.2150845229625702\n",
      "[*] Test roc_auc: 0.7429729845644544\n",
      "\n",
      "[*] Best val loss: 0.19529646635055542 at epoch 19\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 20...\n",
      "[*] Training Loss: 0.22118201851844788\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.18291279673576355\n",
      "mean sig(logit) neg = 0.06090988963842392\n",
      "mean logit pos = -2.013875961303711\n",
      "mean logit neg = -3.0242462158203125\n",
      "[*] Val Loss: 0.19961851835250854\n",
      "[*] Val roc_auc: 0.7258837312465772\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.17671646177768707\n",
      "mean sig(logit) neg = 0.059899233281612396\n",
      "mean logit pos = -2.045316457748413\n",
      "mean logit neg = -3.017833709716797\n",
      "[*] Test Loss: 0.21834112703800201\n",
      "[*] Test roc_auc: 0.7248714547317076\n",
      "\n",
      "[*] Best val loss: 0.19529646635055542 at epoch 19\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 21...\n",
      "[*] Training Loss: 0.21974267065525055\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17656296491622925\n",
      "mean sig(logit) neg = 0.05769660323858261\n",
      "mean logit pos = -2.0330469608306885\n",
      "mean logit neg = -3.0763230323791504\n",
      "[*] Val Loss: 0.19624683260917664\n",
      "[*] Val roc_auc: 0.7429352226954637\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.169200137257576\n",
      "mean sig(logit) neg = 0.05670994892716408\n",
      "mean logit pos = -2.081498384475708\n",
      "mean logit neg = -3.0672898292541504\n",
      "[*] Test Loss: 0.21620874106884003\n",
      "[*] Test roc_auc: 0.7386605228137065\n",
      "\n",
      "[*] Best val loss: 0.19529646635055542 at epoch 19\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 22...\n",
      "[*] Training Loss: 0.22090323269367218\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.18096128106117249\n",
      "mean sig(logit) neg = 0.057876139879226685\n",
      "mean logit pos = -2.019806146621704\n",
      "mean logit neg = -3.080349922180176\n",
      "[*] Val Loss: 0.1963101327419281\n",
      "[*] Val roc_auc: 0.7428873946821188\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1726161539554596\n",
      "mean sig(logit) neg = 0.055853210389614105\n",
      "mean logit pos = -2.076082706451416\n",
      "mean logit neg = -3.094520092010498\n",
      "[*] Test Loss: 0.2154814600944519\n",
      "[*] Test roc_auc: 0.7400951565545055\n",
      "\n",
      "[*] Best val loss: 0.19529646635055542 at epoch 19\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 23...\n",
      "[*] Training Loss: 0.219076469540596\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17631903290748596\n",
      "mean sig(logit) neg = 0.05620766058564186\n",
      "mean logit pos = -2.0393433570861816\n",
      "mean logit neg = -3.105022430419922\n",
      "[*] Val Loss: 0.194876030087471\n",
      "[*] Val roc_auc: 0.7478659005292915\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.164310485124588\n",
      "mean sig(logit) neg = 0.05370939522981644\n",
      "mean logit pos = -2.115114688873291\n",
      "mean logit neg = -3.1299636363983154\n",
      "[*] Test Loss: 0.2145511358976364\n",
      "[*] Test roc_auc: 0.7459898879948897\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 24...\n",
      "[*] Training Loss: 0.21899636089801788\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.15934456884860992\n",
      "mean sig(logit) neg = 0.05107242986559868\n",
      "mean logit pos = -2.1767144203186035\n",
      "mean logit neg = -3.2208449840545654\n",
      "[*] Val Loss: 0.19544626772403717\n",
      "[*] Val roc_auc: 0.7426279194849761\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.14958326518535614\n",
      "mean sig(logit) neg = 0.04953918978571892\n",
      "mean logit pos = -2.234934091567993\n",
      "mean logit neg = -3.2274835109710693\n",
      "[*] Test Loss: 0.2163405418395996\n",
      "[*] Test roc_auc: 0.7423240309653586\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 19 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 25...\n",
      "[*] Training Loss: 0.21852028369903564\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.170932337641716\n",
      "mean sig(logit) neg = 0.0512976348400116\n",
      "mean logit pos = -2.1624927520751953\n",
      "mean logit neg = -3.254283905029297\n",
      "[*] Val Loss: 0.1967107057571411\n",
      "[*] Val roc_auc: 0.7298101008247242\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16254134476184845\n",
      "mean sig(logit) neg = 0.05105375126004219\n",
      "mean logit pos = -2.191105842590332\n",
      "mean logit neg = -3.2277801036834717\n",
      "[*] Test Loss: 0.2170678824186325\n",
      "[*] Test roc_auc: 0.7345973074399278\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 18 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 26...\n",
      "[*] Training Loss: 0.21782785654067993\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1552640050649643\n",
      "mean sig(logit) neg = 0.05072282999753952\n",
      "mean logit pos = -2.2104640007019043\n",
      "mean logit neg = -3.223881959915161\n",
      "[*] Val Loss: 0.19665369391441345\n",
      "[*] Val roc_auc: 0.7356120860918467\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.14571775496006012\n",
      "mean sig(logit) neg = 0.048817362636327744\n",
      "mean logit pos = -2.2602603435516357\n",
      "mean logit neg = -3.237032413482666\n",
      "[*] Test Loss: 0.2168406844139099\n",
      "[*] Test roc_auc: 0.7435091920253396\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 17 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 27...\n",
      "[*] Training Loss: 0.21818210184574127\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1632823795080185\n",
      "mean sig(logit) neg = 0.053709179162979126\n",
      "mean logit pos = -2.166491746902466\n",
      "mean logit neg = -3.205653190612793\n",
      "[*] Val Loss: 0.19841018319129944\n",
      "[*] Val roc_auc: 0.7260122506934796\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1530591994524002\n",
      "mean sig(logit) neg = 0.05160563439130783\n",
      "mean logit pos = -2.2280969619750977\n",
      "mean logit neg = -3.217804193496704\n",
      "[*] Test Loss: 0.2186255156993866\n",
      "[*] Test roc_auc: 0.7283541226973895\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 16 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 28...\n",
      "[*] Training Loss: 0.21880409121513367\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16698744893074036\n",
      "mean sig(logit) neg = 0.05165759101510048\n",
      "mean logit pos = -2.176210403442383\n",
      "mean logit neg = -3.2622032165527344\n",
      "[*] Val Loss: 0.19741365313529968\n",
      "[*] Val roc_auc: 0.7309644818093944\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.15670627355575562\n",
      "mean sig(logit) neg = 0.04910007491707802\n",
      "mean logit pos = -2.241981029510498\n",
      "mean logit neg = -3.2858409881591797\n",
      "[*] Test Loss: 0.21764090657234192\n",
      "[*] Test roc_auc: 0.7321890755234939\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 15 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 29...\n",
      "[*] Training Loss: 0.2184084951877594\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17861686646938324\n",
      "mean sig(logit) neg = 0.05487515404820442\n",
      "mean logit pos = -2.1061604022979736\n",
      "mean logit neg = -3.2060258388519287\n",
      "[*] Val Loss: 0.19828134775161743\n",
      "[*] Val roc_auc: 0.7270146205764312\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16990971565246582\n",
      "mean sig(logit) neg = 0.053198862820863724\n",
      "mean logit pos = -2.143490791320801\n",
      "mean logit neg = -3.209599018096924\n",
      "[*] Test Loss: 0.21714681386947632\n",
      "[*] Test roc_auc: 0.7347640309478785\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 14 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 30...\n",
      "[*] Training Loss: 0.217614084482193\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1750984638929367\n",
      "mean sig(logit) neg = 0.05502801388502121\n",
      "mean logit pos = -2.1184678077697754\n",
      "mean logit neg = -3.1792705059051514\n",
      "[*] Val Loss: 0.19866089522838593\n",
      "[*] Val roc_auc: 0.7215695270735097\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.17051854729652405\n",
      "mean sig(logit) neg = 0.05416066572070122\n",
      "mean logit pos = -2.1331264972686768\n",
      "mean logit neg = -3.1716177463531494\n",
      "[*] Test Loss: 0.21745452284812927\n",
      "[*] Test roc_auc: 0.7295364198431455\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 13 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 31...\n",
      "[*] Training Loss: 0.21719452738761902\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16288405656814575\n",
      "mean sig(logit) neg = 0.05204455554485321\n",
      "mean logit pos = -2.1551578044891357\n",
      "mean logit neg = -3.1896002292633057\n",
      "[*] Val Loss: 0.1956121027469635\n",
      "[*] Val roc_auc: 0.7382770462791823\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1468200832605362\n",
      "mean sig(logit) neg = 0.048520103096961975\n",
      "mean logit pos = -2.267871141433716\n",
      "mean logit neg = -3.2370212078094482\n",
      "[*] Test Loss: 0.21727333962917328\n",
      "[*] Test roc_auc: 0.7392170664066637\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 12 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 32...\n",
      "[*] Training Loss: 0.21738575398921967\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1887345165014267\n",
      "mean sig(logit) neg = 0.0600271075963974\n",
      "mean logit pos = -1.9743711948394775\n",
      "mean logit neg = -3.059608221054077\n",
      "[*] Val Loss: 0.1969134509563446\n",
      "[*] Val roc_auc: 0.7383227136293476\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.17541669309139252\n",
      "mean sig(logit) neg = 0.057063665241003036\n",
      "mean logit pos = -2.0581204891204834\n",
      "mean logit neg = -3.0924887657165527\n",
      "[*] Test Loss: 0.21601766347885132\n",
      "[*] Test roc_auc: 0.7386576042744146\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 11 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 33...\n",
      "[*] Training Loss: 0.2159023880958557\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1760815680027008\n",
      "mean sig(logit) neg = 0.057697977870702744\n",
      "mean logit pos = -2.0513789653778076\n",
      "mean logit neg = -3.093683958053589\n",
      "[*] Val Loss: 0.19716332852840424\n",
      "[*] Val roc_auc: 0.738127453697566\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16231875121593475\n",
      "mean sig(logit) neg = 0.054184649139642715\n",
      "mean logit pos = -2.1423213481903076\n",
      "mean logit neg = -3.136113405227661\n",
      "[*] Test Loss: 0.21668890118598938\n",
      "[*] Test roc_auc: 0.7383323744293007\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 10 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 34...\n",
      "[*] Training Loss: 0.21540769934654236\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.18585769832134247\n",
      "mean sig(logit) neg = 0.057427678257226944\n",
      "mean logit pos = -2.0565547943115234\n",
      "mean logit neg = -3.1760971546173096\n",
      "[*] Val Loss: 0.19937098026275635\n",
      "[*] Val roc_auc: 0.7310263230127434\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1809074431657791\n",
      "mean sig(logit) neg = 0.0556827075779438\n",
      "mean logit pos = -2.070286989212036\n",
      "mean logit neg = -3.1823461055755615\n",
      "[*] Test Loss: 0.21656621992588043\n",
      "[*] Test roc_auc: 0.7366204248306951\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 9 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 35...\n",
      "[*] Training Loss: 0.21441024541854858\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17882874608039856\n",
      "mean sig(logit) neg = 0.058098990470170975\n",
      "mean logit pos = -2.077648878097534\n",
      "mean logit neg = -3.1647071838378906\n",
      "[*] Val Loss: 0.2000376433134079\n",
      "[*] Val roc_auc: 0.7303556727233702\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16573332250118256\n",
      "mean sig(logit) neg = 0.05509444326162338\n",
      "mean logit pos = -2.155555009841919\n",
      "mean logit neg = -3.1982152462005615\n",
      "[*] Test Loss: 0.21944929659366608\n",
      "[*] Test roc_auc: 0.7282744325282723\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 8 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 36...\n",
      "[*] Training Loss: 0.21264171600341797\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.18504419922828674\n",
      "mean sig(logit) neg = 0.06205673888325691\n",
      "mean logit pos = -2.031076431274414\n",
      "mean logit neg = -3.0940937995910645\n",
      "[*] Val Loss: 0.20259040594100952\n",
      "[*] Val roc_auc: 0.7208309270392059\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.17461594939231873\n",
      "mean sig(logit) neg = 0.06157999858260155\n",
      "mean logit pos = -2.0833237171173096\n",
      "mean logit neg = -3.068493366241455\n",
      "[*] Test Loss: 0.222948357462883\n",
      "[*] Test roc_auc: 0.7114568570908987\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 7 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 37...\n",
      "[*] Training Loss: 0.21277542412281036\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.17560988664627075\n",
      "mean sig(logit) neg = 0.06301578879356384\n",
      "mean logit pos = -2.0520200729370117\n",
      "mean logit neg = -3.068542242050171\n",
      "[*] Val Loss: 0.20294369757175446\n",
      "[*] Val roc_auc: 0.7189175842149594\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1623409539461136\n",
      "mean sig(logit) neg = 0.0607248991727829\n",
      "mean logit pos = -2.129779577255249\n",
      "mean logit neg = -3.084012508392334\n",
      "[*] Test Loss: 0.22295241057872772\n",
      "[*] Test roc_auc: 0.7182915532728313\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 6 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 38...\n",
      "[*] Training Loss: 0.21319782733917236\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1773003488779068\n",
      "mean sig(logit) neg = 0.05524169281125069\n",
      "mean logit pos = -2.0922160148620605\n",
      "mean logit neg = -3.1948957443237305\n",
      "[*] Val Loss: 0.19778545200824738\n",
      "[*] Val roc_auc: 0.7371148673455061\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.16645464301109314\n",
      "mean sig(logit) neg = 0.05213082954287529\n",
      "mean logit pos = -2.1813061237335205\n",
      "mean logit neg = -3.2332873344421387\n",
      "[*] Test Loss: 0.2181796133518219\n",
      "[*] Test roc_auc: 0.7292801424397004\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 5 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 39...\n",
      "[*] Training Loss: 0.21368925273418427\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.15721076726913452\n",
      "mean sig(logit) neg = 0.05902954563498497\n",
      "mean logit pos = -2.120323419570923\n",
      "mean logit neg = -3.065553665161133\n",
      "[*] Val Loss: 0.20020191371440887\n",
      "[*] Val roc_auc: 0.7307465749265086\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.14432457089424133\n",
      "mean sig(logit) neg = 0.055903464555740356\n",
      "mean logit pos = -2.22457218170166\n",
      "mean logit neg = -3.1023685932159424\n",
      "[*] Test Loss: 0.22161485254764557\n",
      "[*] Test roc_auc: 0.7210376880499144\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 4 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 40...\n",
      "[*] Training Loss: 0.21199265122413635\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.15234634280204773\n",
      "mean sig(logit) neg = 0.057329755276441574\n",
      "mean logit pos = -2.1735875606536865\n",
      "mean logit neg = -3.091351270675659\n",
      "[*] Val Loss: 0.20102143287658691\n",
      "[*] Val roc_auc: 0.7259788093180954\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1424257755279541\n",
      "mean sig(logit) neg = 0.054383836686611176\n",
      "mean logit pos = -2.2322094440460205\n",
      "mean logit neg = -3.12431001663208\n",
      "[*] Test Loss: 0.22024323046207428\n",
      "[*] Test roc_auc: 0.7307874743410453\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 3 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 41...\n",
      "[*] Training Loss: 0.21012090146541595\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.1469958871603012\n",
      "mean sig(logit) neg = 0.04695252701640129\n",
      "mean logit pos = -2.3235554695129395\n",
      "mean logit neg = -3.4020700454711914\n",
      "[*] Val Loss: 0.1989554911851883\n",
      "[*] Val roc_auc: 0.7383332679799409\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.1288694441318512\n",
      "mean sig(logit) neg = 0.042385831475257874\n",
      "mean logit pos = -2.481069803237915\n",
      "mean logit neg = -3.4805006980895996\n",
      "[*] Test Loss: 0.22357229888439178\n",
      "[*] Test roc_auc: 0.730407455553768\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 2 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 42...\n",
      "[*] Training Loss: 0.21116873621940613\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16686885058879852\n",
      "mean sig(logit) neg = 0.04958278685808182\n",
      "mean logit pos = -2.176600933074951\n",
      "mean logit neg = -3.357403039932251\n",
      "[*] Val Loss: 0.1954483836889267\n",
      "[*] Val roc_auc: 0.7516098229972276\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.15431727468967438\n",
      "mean sig(logit) neg = 0.046143628656864166\n",
      "mean logit pos = -2.3101394176483154\n",
      "mean logit neg = -3.4104840755462646\n",
      "[*] Test Loss: 0.21914632618427277\n",
      "[*] Test roc_auc: 0.732576585748526\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 1 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 43...\n",
      "[*] Training Loss: 0.21003010869026184\n",
      "prevalence = 0.008371403440833092\n",
      "mean sig(logit) pos = 0.16521988809108734\n",
      "mean sig(logit) neg = 0.04632088541984558\n",
      "mean logit pos = -2.231614351272583\n",
      "mean logit neg = -3.457458019256592\n",
      "[*] Val Loss: 0.1950015425682068\n",
      "[*] Val roc_auc: 0.7554652730300242\n",
      "\n",
      "prevalence = 0.009549961425364017\n",
      "mean sig(logit) pos = 0.14728640019893646\n",
      "mean sig(logit) neg = 0.04141181707382202\n",
      "mean logit pos = -2.4024460315704346\n",
      "mean logit neg = -3.552272081375122\n",
      "[*] Test Loss: 0.21956267952919006\n",
      "[*] Test roc_auc: 0.7433398074962698\n",
      "\n",
      "[*] Best val loss: 0.194876030087471 at epoch 23\n",
      "[*] Early stopping in 0 epochs\n",
      "[*] Best Val ROC AUC: 0.7491133056217165 at epoch 19\n",
      "[*] Best Test ROC AUC: 0.7531817072574614 at epoch 11\n",
      "-----------------------------------------------------\n",
      "[*] Early stopping\n",
      "\n",
      "[*] ----------------------------- Iteration: 4 -----------------------------\n",
      "\n",
      "[*] Trial: <optuna.trial._trial.Trial object at 0x77ffde59ae70>\n",
      "[*] HPT: {'memory': 5, 'seed': 43, 'num_layers': 5, 'state_size': 100, 'd_model_factor': 2.0, 'dropout': 0.24605505226601385, 'pos_weight': 8.659809370183545, 'batch_size': 200, 'n_accumulation_steps': 12, 'learning_rate': 0.00010402475347082645, 'rec_learning_factor': 0.5, 'beta1': 0.8677665190811684, 'beta2': 0.999099534403825, 'weight_decay': 0.3209929829580755}\n",
      "[*] Npz file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists with matching meta. Using existing file.\n",
      "\n",
      "[*] -------------------- Dataset Statistics --------------------\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz\n",
      "[*] Number of nodes: 7047\n",
      "[*] Total number of edges used: 411400\n",
      "[*] Val_ratio: 0.2 | Test_ratio: 0.2\n",
      "[*] Number of features: 6\n",
      "[*] -----------------------------------------------------------\n",
      "\n",
      "[*] Trainable Parameters: 1212101\n",
      "[*] Model running on device: cuda:0\n",
      "W1223 19:37:26.122742     669 bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB (rounded to 2255360000)requested by op \n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "W1223 19:37:26.124133     669 bfc_allocator.cc:512] ******************_____________******************_____________________________****____*****_***___**\n",
      "E1223 19:37:26.124239     669 pjrt_stream_executor_client.cc:2085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2.10GiB. [tf-allocator-allocation-error='']\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 1014, in <module>\n",
      "    model_state = init_model()\n",
      "                  ^^^^^^^^^^^^\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 345, in init_model\n",
      "    return (init_model_state(), init_model_traces())\n",
      "                                ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 316, in init_model_traces\n",
      "    B_traces = init_B_traces()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/content/no-time-to-backprop/tgap/memory.py\", line 15, in memory_store\n",
      "    return tree_map(init, unbatched_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/tree_util.py\", line 361, in tree_map\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/tree_util.py\", line 361, in <genexpr>\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "                             ^^^^^^\n",
      "ValueError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2.10GiB.\n",
      "--------------------\n",
      "For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.\n"
     ]
    }
   ],
   "source": [
    "# Optuna trials\n",
    "!python3 run_toy_task.py -m ONLINE -a ZUC --dataset mooc --batching_strategy rearranged --num_epochs 100 --dedupe --hpt optuna --hpt_config ./tgap/benchmarks/hpt_config_example.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30fd0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
