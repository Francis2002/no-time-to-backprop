{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7807525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%rm -rf no-time-to-backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fddc64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n",
      "Wed Dec 17 01:47:35 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   48C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c641917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'no-time-to-backprop'...\n",
      "remote: Enumerating objects: 174, done.\u001b[K\n",
      "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
      "remote: Total 174 (delta 19), reused 20 (delta 7), pack-reused 138 (from 1)\u001b[K\n",
      "Receiving objects: 100% (174/174), 88.24 MiB | 47.18 MiB/s, done.\n",
      "Resolving deltas: 100% (88/88), done.\n",
      "/content/no-time-to-backprop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.80\"\n",
    "\n",
    "!git clone https://github.com/Francis2002/no-time-to-backprop.git\n",
    "%cd no-time-to-backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2939153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n",
      "constraints.txt\t\t\t requirements-macos-cpu.txt  run_on_gpu.ipynb\n",
      "hpt.py\t\t\t\t requirements.mac.txt\t     run_toy_task.py\n",
      "plotting_scripts\t\t requirements.txt\t     test_rec.py\n",
      "requirements-base.txt\t\t run_all_benchmarks.sh\t     tgap\n",
      "requirements.from_linux_env.txt  run_all.sh\n",
      "requirements-linux-cuda.txt\t run_all_toy.sh\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e5e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==2.3.1 (from -r requirements.txt (line 2))\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: alembic==1.17.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: attrs==25.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (25.4.0)\n",
      "Collecting chex==0.1.91 (from -r requirements.txt (line 5))\n",
      "  Downloading chex-0.1.91-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting colorlog==6.10.1 (from -r requirements.txt (line 6))\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy==1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: dm-tree==0.1.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.1.9)\n",
      "Collecting flax==0.12.1 (from -r requirements.txt (line 10))\n",
      "  Downloading flax-0.12.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fonttools==4.61.1 (from -r requirements.txt (line 11))\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m868.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib==1.5.3 (from -r requirements.txt (line 14))\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.4.9)\n",
      "Requirement already satisfied: Mako==1.3.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.3.10)\n",
      "Requirement already satisfied: markdown-it-py==4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (3.0.3)\n",
      "Collecting matplotlib==3.10.8 (from -r requirements.txt (line 19))\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: ml_dtypes==0.5.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (0.5.4)\n",
      "Requirement already satisfied: msgpack==1.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (1.1.2)\n",
      "Collecting numpy==2.3.5 (from -r requirements.txt (line 23))\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt_einsum==3.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (3.4.0)\n",
      "Requirement already satisfied: optax==0.2.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (0.2.6)\n",
      "Collecting optuna==4.6.0 (from -r requirements.txt (line 26))\n",
      "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (25.0)\n",
      "Collecting pandas==2.3.3 (from -r requirements.txt (line 28))\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow==12.0.0 (from -r requirements.txt (line 29))\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: Pygments==2.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (2.19.2)\n",
      "Requirement already satisfied: pyparsing==3.2.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (6.0.3)\n",
      "Collecting rich==14.2.0 (from -r requirements.txt (line 35))\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting scikit-learn==1.8.0 (from -r requirements.txt (line 36))\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy==1.16.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 37)) (1.16.3)\n",
      "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (1.17.0)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.45 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 39)) (2.0.45)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 40)) (3.6.0)\n",
      "Collecting tomli==2.3.0 (from -r requirements.txt (line 41))\n",
      "  Downloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting toolz==1.1.0 (from -r requirements.txt (line 42))\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (4.15.0)\n",
      "Collecting tzdata==2025.3 (from -r requirements.txt (line 45))\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: wrapt==2.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 46)) (2.0.1)\n",
      "Collecting jax==0.8.1 (from jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jaxlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from chex==0.1.91->-r requirements.txt (line 5)) (0.7.2)\n",
      "Collecting orbax-checkpoint (from flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading orbax_checkpoint-0.11.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tensorstore (from flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading tensorstore-0.1.80-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.1->-r requirements.txt (line 10)) (0.1.10)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy==2.0.45->-r requirements.txt (line 39)) (3.3.0)\n",
      "Collecting jaxlib>=0.7.0 (from chex==0.1.91->-r requirements.txt (line 5))\n",
      "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting jax-cuda12-plugin<=0.8.1,>=0.8.1 (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading jax_cuda12_plugin-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting jax-cuda12-pjrt==0.8.1 (from jax-cuda12-plugin<=0.8.1,>=0.8.1->jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading jax_cuda12_pjrt-0.8.1-py3-none-manylinux_2_27_x86_64.whl.metadata (579 bytes)\n",
      "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.80)\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3))\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.8 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12>=12.1.55 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12>=3.2.5 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.8.1,>=0.8.1; extra == \"cuda12\"->jax[cuda12]==0.8.1->-r requirements-linux-cuda.txt (line 3)) (3.3.20)\n",
      "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (1.13.0)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (1.6.0)\n",
      "Collecting aiofiles (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (4.14.0)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (3.20.2)\n",
      "Collecting psutil (from orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Collecting fsspec (from etils[epath,epy]->orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10))\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (6.5.2)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.1->-r requirements.txt (line 10)) (3.23.0)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chex-0.1.91-py3-none-any.whl (100 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading flax-0.12.1-py3-none-any.whl (488 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.2/488.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m138.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.8.1-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax_cuda12_plugin-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax_cuda12_pjrt-0.8.1-py3-none-manylinux_2_27_x86_64.whl (150.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.5/150.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading orbax_checkpoint-0.11.31-py3-none-any.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorstore-0.1.80-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jax-cuda12-pjrt, tzdata, toolz, tomli, psutil, protobuf, pillow, nvidia-cuda-nvcc-cu12, numpy, joblib, jax-cuda12-plugin, fsspec, fonttools, colorlog, aiofiles, absl-py, rich, pandas, tensorstore, scikit-learn, optuna, matplotlib, jaxlib, jax, orbax-checkpoint, chex, flax\n",
      "  Attempting uninstall: jax-cuda12-pjrt\n",
      "    Found existing installation: jax-cuda12-pjrt 0.7.2\n",
      "    Uninstalling jax-cuda12-pjrt-0.7.2:\n",
      "      Successfully uninstalled jax-cuda12-pjrt-0.7.2\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2025.2\n",
      "    Uninstalling tzdata-2025.2:\n",
      "      Successfully uninstalled tzdata-2025.2\n",
      "  Attempting uninstall: toolz\n",
      "    Found existing installation: toolz 0.12.1\n",
      "    Uninstalling toolz-0.12.1:\n",
      "      Successfully uninstalled toolz-0.12.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.5\n",
      "    Uninstalling psutil-5.9.5:\n",
      "      Successfully uninstalled psutil-5.9.5\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.3.0\n",
      "    Uninstalling pillow-11.3.0:\n",
      "      Successfully uninstalled pillow-11.3.0\n",
      "  Attempting uninstall: nvidia-cuda-nvcc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.2\n",
      "    Uninstalling joblib-1.5.2:\n",
      "      Successfully uninstalled joblib-1.5.2\n",
      "  Attempting uninstall: jax-cuda12-plugin\n",
      "    Found existing installation: jax-cuda12-plugin 0.7.2\n",
      "    Uninstalling jax-cuda12-plugin-0.7.2:\n",
      "      Successfully uninstalled jax-cuda12-plugin-0.7.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.61.0\n",
      "    Uninstalling fonttools-4.61.0:\n",
      "      Successfully uninstalled fonttools-4.61.0\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 24.1.0\n",
      "    Uninstalling aiofiles-24.1.0:\n",
      "      Successfully uninstalled aiofiles-24.1.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.4.0\n",
      "    Uninstalling absl-py-1.4.0:\n",
      "      Successfully uninstalled absl-py-1.4.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.9.4\n",
      "    Uninstalling rich-13.9.4:\n",
      "      Successfully uninstalled rich-13.9.4\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: tensorstore\n",
      "    Found existing installation: tensorstore 0.1.79\n",
      "    Uninstalling tensorstore-0.1.79:\n",
      "      Successfully uninstalled tensorstore-0.1.79\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.0\n",
      "    Uninstalling matplotlib-3.10.0:\n",
      "      Successfully uninstalled matplotlib-3.10.0\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.7.2\n",
      "    Uninstalling jaxlib-0.7.2:\n",
      "      Successfully uninstalled jaxlib-0.7.2\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.7.2\n",
      "    Uninstalling jax-0.7.2:\n",
      "      Successfully uninstalled jax-0.7.2\n",
      "  Attempting uninstall: orbax-checkpoint\n",
      "    Found existing installation: orbax-checkpoint 0.11.30\n",
      "    Uninstalling orbax-checkpoint-0.11.30:\n",
      "      Successfully uninstalled orbax-checkpoint-0.11.30\n",
      "  Attempting uninstall: chex\n",
      "    Found existing installation: chex 0.1.90\n",
      "    Uninstalling chex-0.1.90:\n",
      "      Successfully uninstalled chex-0.1.90\n",
      "  Attempting uninstall: flax\n",
      "    Found existing installation: flax 0.10.7\n",
      "    Uninstalling flax-0.10.7:\n",
      "      Successfully uninstalled flax-0.10.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
      "gradio 5.50.0 requires aiofiles<25.0,>=22.0, but you have aiofiles 25.1.0 which is incompatible.\n",
      "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.2 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.2 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.2 which is incompatible.\n",
      "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.3.1 aiofiles-25.1.0 chex-0.1.91 colorlog-6.10.1 flax-0.12.1 fonttools-4.61.1 fsspec-2025.12.0 jax-0.8.1 jax-cuda12-pjrt-0.8.1 jax-cuda12-plugin-0.8.1 jaxlib-0.8.1 joblib-1.5.3 matplotlib-3.10.8 numpy-2.3.5 nvidia-cuda-nvcc-cu12-12.9.86 optuna-4.6.0 orbax-checkpoint-0.11.31 pandas-2.3.3 pillow-12.0.0 protobuf-6.33.2 psutil-7.1.3 rich-14.2.0 scikit-learn-1.8.0 tensorstore-0.1.80 tomli-2.3.0 toolz-1.1.0 tzdata-2025.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "3b90c7fdfb174a2081b5f955b92eb3ad",
       "pip_warning": {
        "packages": [
         "PIL",
         "google",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "psutil"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install -r requirements-linux-cuda.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bb9164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax: 0.8.1\n",
      "jaxlib: 0.8.1\n",
      "executable: /usr/bin/python3\n",
      "devices: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jaxlib\n",
    "import sys\n",
    "\n",
    "print(f\"jax: {jax.__version__}\")\n",
    "print(f\"jaxlib: {jaxlib.__version__}\")\n",
    "print(f\"executable: {sys.executable}\")\n",
    "print(f\"devices: {jax.devices()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5b4113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Results will be stored in /content/no-time-to-backprop/results_for_rotational_vs_none/mooc_ONLINE\n",
      "[*] d_model set to 64\n",
      "Running iteration: 0\n",
      "[*] Output file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists. Using existing file.\n",
      "W1215 17:50:15.106473    6991 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1215 17:50:15.108528    6976 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "[*] Created stream sampler with 288224 events, 7047 nodes (total regardless of splits), feat dim 6, target dim 1\n",
      "Number of positive labels: 2977\n",
      "[*] Created stream sampler with 61762 events, 7047 nodes (total regardless of splits), feat dim 6, target dim 1\n",
      "Number of positive labels: 510\n",
      "[*] Created stream sampler with 61763 events, 7047 nodes (total regardless of splits), feat dim 6, target dim 1\n",
      "Number of positive labels: 579\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz with 7047 nodes\n",
      "[*] Trainable Parameters: 9665\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- encoder\n",
      "|  |  |  |- layers_0\n",
      "|  |  |  |  |- seq\n",
      "|  |  |  |     |- theta  shape=(128,)\n",
      "|  |  |  |     |- nu  shape=(128,)\n",
      "|  |  |  |     |- gamma_log  shape=(64,)\n",
      "|  |  |  |     |- B_re  shape=(64, 6)\n",
      "|  |  |  |     |- B_im  shape=(64, 6)\n",
      "|  |  |  |- layers_1\n",
      "|  |  |     |- seq\n",
      "|  |  |        |- theta  shape=(128,)\n",
      "|  |  |        |- nu  shape=(128,)\n",
      "|  |  |        |- gamma_log  shape=(64,)\n",
      "|  |  |        |- B_re  shape=(64, 64)\n",
      "|  |  |        |- B_im  shape=(64, 64)\n",
      "|  |  |- decoder\n",
      "|  |     |- kernel  shape=(64, 1)\n",
      "|  |     |- bias  shape=(1,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64,)\n",
      "|        |- layers_1\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(64,)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "[*] Training Loss: 0.05615294352173805\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.5156345963478088\n",
      "mean sig(logit) neg = 0.345583438873291\n",
      "mean logit pos = 0.07871177792549133\n",
      "mean logit neg = -0.721745491027832\n",
      "[*] Val Loss: 0.46734920144081116\n",
      "[*] Val roc_auc: 0.7050933270846378\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.4847238063812256\n",
      "mean sig(logit) neg = 0.3356035351753235\n",
      "mean logit pos = -0.07084119319915771\n",
      "mean logit neg = -0.7705649733543396\n",
      "[*] Test Loss: 0.45105627179145813\n",
      "[*] Test roc_auc: 0.6834143172879585\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 2...\n",
      "[*] Training Loss: 0.054661333560943604\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.4039169251918793\n",
      "mean sig(logit) neg = 0.23220153152942657\n",
      "mean logit pos = -0.5134353041648865\n",
      "mean logit neg = -1.3681833744049072\n",
      "[*] Val Loss: 0.29520711302757263\n",
      "[*] Val roc_auc: 0.7026433870746758\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.3674916625022888\n",
      "mean sig(logit) neg = 0.22180874645709991\n",
      "mean logit pos = -0.7111620306968689\n",
      "mean logit neg = -1.4272199869155884\n",
      "[*] Test Loss: 0.28104791045188904\n",
      "[*] Test roc_auc: 0.6738497619344419\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 3...\n",
      "[*] Training Loss: 0.05446939170360565\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.30261531472206116\n",
      "mean sig(logit) neg = 0.15796060860157013\n",
      "mean logit pos = -1.0785139799118042\n",
      "mean logit neg = -1.9027771949768066\n",
      "[*] Val Loss: 0.19493325054645538\n",
      "[*] Val roc_auc: 0.7026788080869388\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.27361205220222473\n",
      "mean sig(logit) neg = 0.1498270332813263\n",
      "mean logit pos = -1.2610502243041992\n",
      "mean logit neg = -1.9610488414764404\n",
      "[*] Test Loss: 0.18638043105602264\n",
      "[*] Test roc_auc: 0.6748566344910067\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 4...\n",
      "[*] Training Loss: 0.05429905652999878\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.2523826062679291\n",
      "mean sig(logit) neg = 0.12738865613937378\n",
      "mean logit pos = -1.3539714813232422\n",
      "mean logit neg = -2.140209197998047\n",
      "[*] Val Loss: 0.15559488534927368\n",
      "[*] Val roc_auc: 0.7028369781923087\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.23283088207244873\n",
      "mean sig(logit) neg = 0.12450442463159561\n",
      "mean logit pos = -1.4993354082107544\n",
      "mean logit neg = -2.166012763977051\n",
      "[*] Test Loss: 0.1548330932855606\n",
      "[*] Test roc_auc: 0.6702981854671162\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 5...\n",
      "[*] Training Loss: 0.054151467978954315\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.14883622527122498\n",
      "mean sig(logit) neg = 0.06976060569286346\n",
      "mean logit pos = -2.0841856002807617\n",
      "mean logit neg = -2.833017587661743\n",
      "[*] Val Loss: 0.09229900687932968\n",
      "[*] Val roc_auc: 0.7038842749272372\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.13445962965488434\n",
      "mean sig(logit) neg = 0.06718061119318008\n",
      "mean logit pos = -2.255486249923706\n",
      "mean logit neg = -2.870189666748047\n",
      "[*] Test Loss: 0.09333861619234085\n",
      "[*] Test roc_auc: 0.6650720401238248\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 6...\n",
      "[*] Training Loss: 0.05415068194270134\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.09145466983318329\n",
      "mean sig(logit) neg = 0.04052786901593208\n",
      "mean logit pos = -2.689457416534424\n",
      "mean logit neg = -3.438884973526001\n",
      "[*] Val Loss: 0.064786396920681\n",
      "[*] Val roc_auc: 0.7040453581027526\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.08205313980579376\n",
      "mean sig(logit) neg = 0.03908570483326912\n",
      "mean logit pos = -2.8798725605010986\n",
      "mean logit neg = -3.4730000495910645\n",
      "[*] Test Loss: 0.0680447593331337\n",
      "[*] Test roc_auc: 0.658302220183768\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 7...\n",
      "[*] Training Loss: 0.054027970880270004\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.07220859825611115\n",
      "mean sig(logit) neg = 0.032472141087055206\n",
      "mean logit pos = -2.9351112842559814\n",
      "mean logit neg = -3.656602621078491\n",
      "[*] Val Loss: 0.058081068098545074\n",
      "[*] Val roc_auc: 0.7046049236647575\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.06481853872537613\n",
      "mean sig(logit) neg = 0.031076127663254738\n",
      "mean logit pos = -3.112166166305542\n",
      "mean logit neg = -3.690002918243408\n",
      "[*] Test Loss: 0.061502743512392044\n",
      "[*] Test roc_auc: 0.6621434746957674\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7050933270846378 at epoch 1\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 8...\n",
      "[*] Training Loss: 0.05392022430896759\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.06346279382705688\n",
      "mean sig(logit) neg = 0.02745860442519188\n",
      "mean logit pos = -3.097118854522705\n",
      "mean logit neg = -3.8334364891052246\n",
      "[*] Val Loss: 0.054095443338155746\n",
      "[*] Val roc_auc: 0.7072296798952064\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.05764615163207054\n",
      "mean sig(logit) neg = 0.02689843811094761\n",
      "mean logit pos = -3.2524774074554443\n",
      "mean logit neg = -3.850536346435547\n",
      "[*] Test Loss: 0.05839100480079651\n",
      "[*] Test roc_auc: 0.663832312939457\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 9...\n",
      "[*] Training Loss: 0.053965598344802856\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.049742456525564194\n",
      "mean sig(logit) neg = 0.02136210910975933\n",
      "mean logit pos = -3.3802194595336914\n",
      "mean logit neg = -4.1195197105407715\n",
      "[*] Val Loss: 0.049998052418231964\n",
      "[*] Val roc_auc: 0.7066014010907047\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.043838270008563995\n",
      "mean sig(logit) neg = 0.020056627690792084\n",
      "mean logit pos = -3.5615124702453613\n",
      "mean logit neg = -4.15981912612915\n",
      "[*] Test Loss: 0.05408275127410889\n",
      "[*] Test roc_auc: 0.6628247911337177\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 10...\n",
      "[*] Training Loss: 0.054049331694841385\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.047568999230861664\n",
      "mean sig(logit) neg = 0.0214850977063179\n",
      "mean logit pos = -3.4109461307525635\n",
      "mean logit neg = -4.110341548919678\n",
      "[*] Val Loss: 0.050367288291454315\n",
      "[*] Val roc_auc: 0.6989013564022879\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.04262984171509743\n",
      "mean sig(logit) neg = 0.020255805924534798\n",
      "mean logit pos = -3.5735297203063965\n",
      "mean logit neg = -4.140636920928955\n",
      "[*] Test Loss: 0.054378923028707504\n",
      "[*] Test roc_auc: 0.6567897377755978\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 11...\n",
      "[*] Training Loss: 0.053985852748155594\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.05599091202020645\n",
      "mean sig(logit) neg = 0.024599308148026466\n",
      "mean logit pos = -3.2345569133758545\n",
      "mean logit neg = -3.956040620803833\n",
      "[*] Val Loss: 0.05217890813946724\n",
      "[*] Val roc_auc: 0.7052370918980797\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.05024728178977966\n",
      "mean sig(logit) neg = 0.023746944963932037\n",
      "mean logit pos = -3.4005300998687744\n",
      "mean logit neg = -3.9807205200195312\n",
      "[*] Test Loss: 0.05642902851104736\n",
      "[*] Test roc_auc: 0.6575727746222386\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 12...\n",
      "[*] Training Loss: 0.054087165743112564\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.04231114313006401\n",
      "mean sig(logit) neg = 0.01935497298836708\n",
      "mean logit pos = -3.5308361053466797\n",
      "mean logit neg = -4.214795112609863\n",
      "[*] Val Loss: 0.049096301198005676\n",
      "[*] Val roc_auc: 0.6970497481954971\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.0385623537003994\n",
      "mean sig(logit) neg = 0.018483173102140427\n",
      "mean logit pos = -3.683199882507324\n",
      "mean logit neg = -4.234431266784668\n",
      "[*] Test Loss: 0.05354251340031624\n",
      "[*] Test roc_auc: 0.6513745338955492\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 13...\n",
      "[*] Training Loss: 0.054131366312503815\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.03997635468840599\n",
      "mean sig(logit) neg = 0.017554668709635735\n",
      "mean logit pos = -3.6194634437561035\n",
      "mean logit neg = -4.310751914978027\n",
      "[*] Val Loss: 0.04795359447598457\n",
      "[*] Val roc_auc: 0.6905584995704022\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.03552985191345215\n",
      "mean sig(logit) neg = 0.016666878014802933\n",
      "mean logit pos = -3.7791848182678223\n",
      "mean logit neg = -4.339635372161865\n",
      "[*] Test Loss: 0.052552226930856705\n",
      "[*] Test roc_auc: 0.6481263120478967\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 14...\n",
      "[*] Training Loss: 0.05404909327626228\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.12838633358478546\n",
      "mean sig(logit) neg = 0.0545964315533638\n",
      "mean logit pos = -2.328197479248047\n",
      "mean logit neg = -3.0965538024902344\n",
      "[*] Val Loss: 0.07748910039663315\n",
      "[*] Val roc_auc: 0.6991103131646442\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.11828114092350006\n",
      "mean sig(logit) neg = 0.05346877872943878\n",
      "mean logit pos = -2.4601759910583496\n",
      "mean logit neg = -3.120105266571045\n",
      "[*] Test Loss: 0.08009684085845947\n",
      "[*] Test roc_auc: 0.6660326748478838\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 15...\n",
      "[*] Training Loss: 0.05402980372309685\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.047603849321603775\n",
      "mean sig(logit) neg = 0.019680678844451904\n",
      "mean logit pos = -3.4560065269470215\n",
      "mean logit neg = -4.208254814147949\n",
      "[*] Val Loss: 0.0488763228058815\n",
      "[*] Val roc_auc: 0.7020882391355289\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.04745877906680107\n",
      "mean sig(logit) neg = 0.021164800971746445\n",
      "mean logit pos = -3.5035717487335205\n",
      "mean logit neg = -4.109415531158447\n",
      "[*] Test Loss: 0.05473335459828377\n",
      "[*] Test roc_auc: 0.6538679612356465\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 16...\n",
      "[*] Training Loss: 0.054044514894485474\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.03460078313946724\n",
      "mean sig(logit) neg = 0.01442138385027647\n",
      "mean logit pos = -3.7984323501586914\n",
      "mean logit neg = -4.558140277862549\n",
      "[*] Val Loss: 0.04621720314025879\n",
      "[*] Val roc_auc: 0.7058951416392326\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.02976921573281288\n",
      "mean sig(logit) neg = 0.013399215415120125\n",
      "mean logit pos = -3.9730842113494873\n",
      "mean logit neg = -4.585530757904053\n",
      "[*] Test Loss: 0.05100199207663536\n",
      "[*] Test roc_auc: 0.664078801799922\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 17...\n",
      "[*] Training Loss: 0.05468927323818207\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.03646688535809517\n",
      "mean sig(logit) neg = 0.016227880492806435\n",
      "mean logit pos = -3.697561264038086\n",
      "mean logit neg = -4.380979537963867\n",
      "[*] Val Loss: 0.04720092937350273\n",
      "[*] Val roc_auc: 0.6953124539830953\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.03324741870164871\n",
      "mean sig(logit) neg = 0.015600325539708138\n",
      "mean logit pos = -3.837125301361084\n",
      "mean logit neg = -4.401489734649658\n",
      "[*] Test Loss: 0.05197537690401077\n",
      "[*] Test roc_auc: 0.6516565338630304\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 18...\n",
      "[*] Training Loss: 0.05481039732694626\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.021756820380687714\n",
      "mean sig(logit) neg = 0.009524784050881863\n",
      "mean logit pos = -4.276002883911133\n",
      "mean logit neg = -4.972121238708496\n",
      "[*] Val Loss: 0.045068953186273575\n",
      "[*] Val roc_auc: 0.6912677041037796\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.01957891322672367\n",
      "mean sig(logit) neg = 0.00903982762247324\n",
      "mean logit pos = -4.413660526275635\n",
      "mean logit neg = -4.97222900390625\n",
      "[*] Test Loss: 0.05060115456581116\n",
      "[*] Test roc_auc: 0.6501548064085749\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 19...\n",
      "[*] Training Loss: 0.054926592856645584\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.051957979798316956\n",
      "mean sig(logit) neg = 0.0212692953646183\n",
      "mean logit pos = -3.3513827323913574\n",
      "mean logit neg = -4.118195533752441\n",
      "[*] Val Loss: 0.04968166723847389\n",
      "[*] Val roc_auc: 0.7049858476009747\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.04813392087817192\n",
      "mean sig(logit) neg = 0.02066849358379841\n",
      "mean logit pos = -3.5031440258026123\n",
      "mean logit neg = -4.152480602264404\n",
      "[*] Test Loss: 0.05420120432972908\n",
      "[*] Test roc_auc: 0.6661780360923826\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 20...\n",
      "[*] Training Loss: 0.054929960519075394\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.02613205835223198\n",
      "mean sig(logit) neg = 0.011121350340545177\n",
      "mean logit pos = -4.109560012817383\n",
      "mean logit neg = -4.815613746643066\n",
      "[*] Val Loss: 0.0453139953315258\n",
      "[*] Val roc_auc: 0.6848093795736802\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.026651550084352493\n",
      "mean sig(logit) neg = 0.01135844737291336\n",
      "mean logit pos = -4.1801934242248535\n",
      "mean logit neg = -4.782812595367432\n",
      "[*] Test Loss: 0.05083417519927025\n",
      "[*] Test roc_auc: 0.646668902906649\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 21...\n",
      "[*] Training Loss: 0.054599761962890625\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.038214683532714844\n",
      "mean sig(logit) neg = 0.01661587506532669\n",
      "mean logit pos = -3.675208568572998\n",
      "mean logit neg = -4.39136266708374\n",
      "[*] Val Loss: 0.04744299128651619\n",
      "[*] Val roc_auc: 0.6947341295298239\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.03519013896584511\n",
      "mean sig(logit) neg = 0.015995841473340988\n",
      "mean logit pos = -3.815018892288208\n",
      "mean logit neg = -4.416545867919922\n",
      "[*] Test Loss: 0.05219876766204834\n",
      "[*] Test roc_auc: 0.6596292854962026\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 22...\n",
      "[*] Training Loss: 0.05461294203996658\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.03975389897823334\n",
      "mean sig(logit) neg = 0.0166770052164793\n",
      "mean logit pos = -3.6490495204925537\n",
      "mean logit neg = -4.390498161315918\n",
      "[*] Val Loss: 0.047316864132881165\n",
      "[*] Val roc_auc: 0.6981536737335827\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.038583945482969284\n",
      "mean sig(logit) neg = 0.016776341944932938\n",
      "mean logit pos = -3.757166624069214\n",
      "mean logit neg = -4.3804426193237305\n",
      "[*] Test Loss: 0.05249971151351929\n",
      "[*] Test roc_auc: 0.6565009912623481\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7072296798952064 at epoch 8\n",
      "[*] Best Test ROC AUC: 0.6834143172879585 at epoch 1\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 23...\n",
      "[*] Training Loss: 0.05529084801673889\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.060206808149814606\n",
      "mean sig(logit) neg = 0.020421961322426796\n",
      "mean logit pos = -3.3019514083862305\n",
      "mean logit neg = -4.198806285858154\n",
      "[*] Val Loss: 0.0485021248459816\n",
      "[*] Val roc_auc: 0.7160556902183586\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.0580170713365078\n",
      "mean sig(logit) neg = 0.021125497296452522\n",
      "mean logit pos = -3.3835220336914062\n",
      "mean logit neg = -4.184970855712891\n",
      "[*] Test Loss: 0.05373159050941467\n",
      "[*] Test roc_auc: 0.6941107821205584\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7160556902183586 at epoch 23\n",
      "[*] Best Test ROC AUC: 0.6941107821205584 at epoch 23\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 24...\n",
      "[*] Training Loss: 0.0544731505215168\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.009411606006324291\n",
      "mean sig(logit) neg = 0.003913062158972025\n",
      "mean logit pos = -5.1878814697265625\n",
      "mean logit neg = -5.953658580780029\n",
      "[*] Val Loss: 0.04682184010744095\n",
      "[*] Val roc_auc: 0.7070024284121015\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.009898103773593903\n",
      "mean sig(logit) neg = 0.004662807565182447\n",
      "mean logit pos = -5.114634037017822\n",
      "mean logit neg = -5.653787136077881\n",
      "[*] Test Loss: 0.05268358066678047\n",
      "[*] Test roc_auc: 0.646857636818819\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7160556902183586 at epoch 23\n",
      "[*] Best Test ROC AUC: 0.6941107821205584 at epoch 23\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 25...\n",
      "[*] Training Loss: 0.0541168674826622\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.10966921597719193\n",
      "mean sig(logit) neg = 0.04091067612171173\n",
      "mean logit pos = -2.617187261581421\n",
      "mean logit neg = -3.4823734760284424\n",
      "[*] Val Loss: 0.06511826813220978\n",
      "[*] Val roc_auc: 0.7037487691478341\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.09886433929204941\n",
      "mean sig(logit) neg = 0.036953382194042206\n",
      "mean logit pos = -2.8055529594421387\n",
      "mean logit neg = -3.6224429607391357\n",
      "[*] Test Loss: 0.0656527653336525\n",
      "[*] Test roc_auc: 0.6906884344671596\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7160556902183586 at epoch 23\n",
      "[*] Best Test ROC AUC: 0.6941107821205584 at epoch 23\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 26...\n",
      "[*] Training Loss: 0.0541997030377388\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.01442980207502842\n",
      "mean sig(logit) neg = 0.008617151528596878\n",
      "mean logit pos = -4.795139312744141\n",
      "mean logit neg = -5.269811630249023\n",
      "[*] Val Loss: 0.04836244508624077\n",
      "[*] Val roc_auc: 0.6254946937306889\n",
      "\n",
      "prevalence = 0.009374544024467468\n",
      "mean sig(logit) pos = 0.01904599368572235\n",
      "mean sig(logit) neg = 0.011098448187112808\n",
      "mean logit pos = -4.553131580352783\n",
      "mean logit neg = -4.901357173919678\n",
      "[*] Test Loss: 0.054015327244997025\n",
      "[*] Test roc_auc: 0.5898634674151437\n",
      "\n",
      "[*] Best Val ROC AUC: 0.7160556902183586 at epoch 23\n",
      "[*] Best Test ROC AUC: 0.6941107821205584 at epoch 23\n",
      "-----------------------------------------------------\n",
      "[*] Starting Training Epoch 27...\n",
      "[*] Training Loss: 0.05443388223648071\n",
      "prevalence = 0.008257504552602768\n",
      "mean sig(logit) pos = 0.04680619761347771\n",
      "mean sig(logit) neg = 0.01822257973253727\n",
      "mean logit pos = -3.4940459728240967\n",
      "mean logit neg = -4.266277313232422\n",
      "[*] Val Loss: 0.04765227809548378\n",
      "[*] Val roc_auc: 0.7072504075097027\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 961, in <module>\n",
      "    (params, optimizer_state, test_data_state, _, _), test_loss = unrolled_test_episode(no_training_state)\n",
      "                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 run_toy_task.py -m ONLINE -a ZUC --dataset mooc --task link_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34c9a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Results will be stored in /content/no-time-to-backprop/results_for_rotational_vs_none/mooc_ONLINE\n",
      "[*] d_model set to 64\n",
      "Running iteration: 0\n",
      "[*] Output file /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz already exists. Using existing file.\n",
      "W1217 01:51:39.782578    1398 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1217 01:51:39.784618    1383 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "[*] Created stream sampler with 288224 events, 7047 nodes (total regardless of splits), feat dim 6, target dim 1\n",
      "Number of positive labels: 2977\n",
      "[*] Created stream sampler with 61762 events, 7047 nodes (total regardless of splits), feat dim 6, target dim 1\n",
      "Number of positive labels: 510\n",
      "[*] Created stream sampler with 61763 events, 7047 nodes (total regardless of splits), feat dim 6, target dim 1\n",
      "Number of positive labels: 579\n",
      "[*] Loaded data from /content/no-time-to-backprop/tgap/data/npzs/mooc_stream.npz with 7047 nodes\n",
      "[*] Trainable Parameters: 302337\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- decoder\n",
      "|  |  |  |- bias  shape=(1,)\n",
      "|  |  |  |- kernel  shape=(64, 1)\n",
      "|  |  |- encoder\n",
      "|  |     |- encoder\n",
      "|  |     |  |- bias  shape=(64,)\n",
      "|  |     |  |- kernel  shape=(6, 64)\n",
      "|  |     |- layers_0\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- scale  shape=(64,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- kernel  shape=(64, 64)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- kernel  shape=(64, 64)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(256, 64)\n",
      "|  |     |     |- B_re  shape=(256, 64)\n",
      "|  |     |     |- C_im  shape=(64, 256)\n",
      "|  |     |     |- C_re  shape=(64, 256)\n",
      "|  |     |     |- D  shape=(64,)\n",
      "|  |     |     |- gamma_log  shape=(256,)\n",
      "|  |     |     |- nu  shape=(512,)\n",
      "|  |     |     |- phi  shape=(128,)\n",
      "|  |     |     |- theta  shape=(512,)\n",
      "|  |     |- layers_1\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- scale  shape=(64,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- kernel  shape=(64, 64)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- kernel  shape=(64, 64)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(256, 64)\n",
      "|  |     |     |- B_re  shape=(256, 64)\n",
      "|  |     |     |- C_im  shape=(64, 256)\n",
      "|  |     |     |- C_re  shape=(64, 256)\n",
      "|  |     |     |- D  shape=(64,)\n",
      "|  |     |     |- gamma_log  shape=(256,)\n",
      "|  |     |     |- nu  shape=(512,)\n",
      "|  |     |     |- phi  shape=(128,)\n",
      "|  |     |     |- theta  shape=(512,)\n",
      "|  |     |- layers_2\n",
      "|  |     |  |- norm\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- scale  shape=(64,)\n",
      "|  |     |  |- out1\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- kernel  shape=(64, 64)\n",
      "|  |     |  |- out2\n",
      "|  |     |  |  |- bias  shape=(64,)\n",
      "|  |     |  |  |- kernel  shape=(64, 64)\n",
      "|  |     |  |- seq\n",
      "|  |     |     |- B_im  shape=(256, 64)\n",
      "|  |     |     |- B_re  shape=(256, 64)\n",
      "|  |     |     |- C_im  shape=(64, 256)\n",
      "|  |     |     |- C_re  shape=(64, 256)\n",
      "|  |     |     |- D  shape=(64,)\n",
      "|  |     |     |- gamma_log  shape=(256,)\n",
      "|  |     |     |- nu  shape=(512,)\n",
      "|  |     |     |- phi  shape=(128,)\n",
      "|  |     |     |- theta  shape=(512,)\n",
      "|  |     |- layers_3\n",
      "|  |        |- norm\n",
      "|  |        |  |- bias  shape=(64,)\n",
      "|  |        |  |- scale  shape=(64,)\n",
      "|  |        |- out1\n",
      "|  |        |  |- bias  shape=(64,)\n",
      "|  |        |  |- kernel  shape=(64, 64)\n",
      "|  |        |- out2\n",
      "|  |        |  |- bias  shape=(64,)\n",
      "|  |        |  |- kernel  shape=(64, 64)\n",
      "|  |        |- seq\n",
      "|  |           |- B_im  shape=(256, 64)\n",
      "|  |           |- B_re  shape=(256, 64)\n",
      "|  |           |- C_im  shape=(64, 256)\n",
      "|  |           |- C_re  shape=(64, 256)\n",
      "|  |           |- D  shape=(64,)\n",
      "|  |           |- gamma_log  shape=(256,)\n",
      "|  |           |- nu  shape=(512,)\n",
      "|  |           |- phi  shape=(128,)\n",
      "|  |           |- theta  shape=(512,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 256)\n",
      "|        |- layers_1\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 256)\n",
      "|        |- layers_2\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(50, 256)\n",
      "|        |- layers_3\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(50, 256)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py:5518: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling setter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "compiling getter...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 916, in <module>\n",
      "    (params, optimizer_state, data_state, model_state_for_val, grads_for_debug), l = unrolled_episode(state)\n",
      "                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 574, in unrolled_episode\n",
      "    (accumulator, data_state, model_state, optimizer_state, params), loss = lax.scan(episodic_step, (accumulator, data_state, model_state, optimizer_state, params), None, num_steps)\n",
      "                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/traceback_util.py\", line 195, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lax/control_flow/loops.py\", line 266, in scan\n",
      "    carry, y = f(carry, tree_unflatten(xs_tree, xs_slice))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 564, in episodic_step\n",
      "    updates, optimizer_state = optimizer.update(grads, optimizer_state, params)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/transforms/_accumulation.py\", line 415, in update\n",
      "    new_updates, new_state = lax.cond(\n",
      "                             ^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/traceback_util.py\", line 195, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lax/control_flow/conditionals.py\", line 419, in cond\n",
      "    return _cond(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/traceback_util.py\", line 195, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lax/control_flow/conditionals.py\", line 261, in _cond\n",
      "    return false_fun(*operands)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/transforms/_accumulation.py\", line 359, in _do_update\n",
      "    final_updates, new_inner_state = self._opt.update(\n",
      "                                     ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/transforms/_combining.py\", line 283, in update_fn\n",
      "    updates, new_inner_state[group] = masked_tx.update(\n",
      "                                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/transforms/_masking.py\", line 137, in update_fn\n",
      "    new_masked_updates, new_inner_state = inner.update(\n",
      "                                          ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/transforms/_combining.py\", line 90, in update_fn\n",
      "    updates, new_s = fn(updates, s, params, **extra_args)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/_src/base.py\", line 336, in update\n",
      "    return tx.update(updates, state, params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/_src/transform.py\", line 283, in update_fn\n",
      "    mu = optax.tree.update_moment(updates, state.mu, b1, 1)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/tree_utils/_tree_math.py\", line 355, in tree_update_moment\n",
      "    return jax.tree.map(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/tree.py\", line 155, in map\n",
      "    return tree_util.tree_map(f, tree, *rest, is_leaf=is_leaf)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/tree_util.py\", line 361, in tree_map\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/tree_util.py\", line 361, in <genexpr>\n",
      "    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "                             ^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optax/tree_utils/_tree_math.py\", line 357, in <lambda>\n",
      "    (1 - decay) * (g**order) + decay * t if g is not None else None\n",
      "                               ~~~~~~^~~\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/numpy/array_methods.py\", line 608, in deferring_binary_op\n",
      "    return binary_op(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/numpy/ufunc_api.py\", line 182, in __call__\n",
      "    return call(*args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/numpy/ufuncs.py\", line 1280, in multiply\n",
      "    x, y = promote_args(\"multiply\", x, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/numpy/util.py\", line 229, in promote_args\n",
      "    return promote_shapes(fun_name, *promote_dtypes(*args))\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/numpy/util.py\", line 93, in promote_dtypes\n",
      "    return [lax._convert_element_type(x, to_dtype, weak_type) for x in args]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py\", line 1727, in _convert_element_type\n",
      "    return convert_element_type_p.bind(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\", line 632, in bind\n",
      "    return self._true_bind(*args, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\", line 648, in _true_bind\n",
      "    return self.bind_with_trace(prev_trace, args, params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py\", line 5035, in _convert_element_type_bind_with_trace\n",
      "    operand = core.Primitive.bind_with_trace(convert_element_type_p, trace, args, params)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\", line 660, in bind_with_trace\n",
      "    return trace.process_primitive(self, args, params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\", line 1189, in process_primitive\n",
      "    return primitive.impl(*args, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/dispatch.py\", line 92, in apply_primitive\n",
      "    outs = fun(*args)\n",
      "           ^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/traceback_util.py\", line 195, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/pjit.py\", line 264, in cache_miss\n",
      "    executable, pgle_profiler, const_args) = _python_pjit_helper(\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/pjit.py\", line 146, in _python_pjit_helper\n",
      "    out_flat, compiled, profiler, const_args = _pjit_call_impl_python(\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/pjit.py\", line 1642, in _pjit_call_impl_python\n",
      "    return (compiled.unsafe_call(*computation.const_args, *args),\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/profiler.py\", line 359, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\", line 1366, in __call__\n",
      "    input_bufs = self.in_handler(args)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\", line 1249, in __call__\n",
      "    return self.handler(input_buffers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/profiler.py\", line 359, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\", line 125, in shard_args\n",
      "    return shard_arg_handlers[type(arg)]([arg], shardings, layouts,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\", line 225, in _shard_typed_scalar\n",
      "    return _shard_np_array(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\", line 211, in _shard_np_array\n",
      "    results.append(batched_device_put(aval, sharding, shards, devices))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\", line 256, in batched_device_put\n",
      "    return xc.batched_device_put(aval, sharding, xs, list(devices), committed,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python3 run_toy_task.py -m ONLINE -a ZUC --num_layers 4 --num_hidden 128 --activation full_glu --decoder MLP --mixing rotational_full --prenorm --encoder --layer_output --extra_skip --dataset mooc --task link_classification --batching_strategy none --lr 0.01 --dropout 0.1 --weight_decay 0.005 --batch_size 50 --num_epochs 200 --num_gradient_accumulation_steps 32 --dedupe --steps_for_scheduler 100 --lr_schedule cosine --rec_lr_schedule cosine --lr_min 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62691497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Results will be stored in /content/no-time-to-backprop/results_for_rotational_vs_none/toy_ONLINE\n",
      "[*] NOT STORING RESULTS!!! to disk as per user request.\n",
      "[*] d_model set to 16\n",
      "[*] Forcing task to be link_regression, because dataset does not support classification\n",
      "Running iteration: 0\n",
      "[*] Created toy data with 100 nodes\n",
      "W1215 13:53:10.118872    8385 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1215 13:53:10.120944    8364 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "[*] Trainable Parameters: 10129\n",
      "[*] Model running on device: cuda:0\n",
      "All params tree leaf keys:\n",
      "|- cell\n",
      "|  |- params\n",
      "|  |  |- encoder\n",
      "|  |  |  |- encoder\n",
      "|  |  |  |  |- kernel  shape=(1, 16)\n",
      "|  |  |  |  |- bias  shape=(16,)\n",
      "|  |  |  |- layers_0\n",
      "|  |  |  |  |- norm\n",
      "|  |  |  |  |  |- scale  shape=(16,)\n",
      "|  |  |  |  |  |- bias  shape=(16,)\n",
      "|  |  |  |  |- seq\n",
      "|  |  |  |  |  |- theta  shape=(128,)\n",
      "|  |  |  |  |  |- nu  shape=(128,)\n",
      "|  |  |  |  |  |- gamma_log  shape=(64,)\n",
      "|  |  |  |  |  |- B_re  shape=(64, 16)\n",
      "|  |  |  |  |  |- B_im  shape=(64, 16)\n",
      "|  |  |  |  |  |- C_re  shape=(16, 64)\n",
      "|  |  |  |  |  |- C_im  shape=(16, 64)\n",
      "|  |  |  |  |  |- D  shape=(16,)\n",
      "|  |  |  |  |  |- phi  shape=(32,)\n",
      "|  |  |  |  |- out1\n",
      "|  |  |  |  |  |- kernel  shape=(16, 16)\n",
      "|  |  |  |  |  |- bias  shape=(16,)\n",
      "|  |  |  |  |- out2\n",
      "|  |  |  |     |- kernel  shape=(16, 16)\n",
      "|  |  |  |     |- bias  shape=(16,)\n",
      "|  |  |  |- layers_1\n",
      "|  |  |     |- norm\n",
      "|  |  |     |  |- scale  shape=(16,)\n",
      "|  |  |     |  |- bias  shape=(16,)\n",
      "|  |  |     |- seq\n",
      "|  |  |     |  |- theta  shape=(128,)\n",
      "|  |  |     |  |- nu  shape=(128,)\n",
      "|  |  |     |  |- gamma_log  shape=(64,)\n",
      "|  |  |     |  |- B_re  shape=(64, 16)\n",
      "|  |  |     |  |- B_im  shape=(64, 16)\n",
      "|  |  |     |  |- C_re  shape=(16, 64)\n",
      "|  |  |     |  |- C_im  shape=(16, 64)\n",
      "|  |  |     |  |- D  shape=(16,)\n",
      "|  |  |     |  |- phi  shape=(32,)\n",
      "|  |  |     |- out1\n",
      "|  |  |     |  |- kernel  shape=(16, 16)\n",
      "|  |  |     |  |- bias  shape=(16,)\n",
      "|  |  |     |- out2\n",
      "|  |  |        |- kernel  shape=(16, 16)\n",
      "|  |  |        |- bias  shape=(16,)\n",
      "|  |  |- decoder\n",
      "|  |     |- kernel  shape=(16, 1)\n",
      "|  |     |- bias  shape=(1,)\n",
      "|  |- perturbations\n",
      "|     |- encoder\n",
      "|        |- layers_0\n",
      "|        |  |- seq\n",
      "|        |     |- hidden_states  shape=(64,)\n",
      "|        |- layers_1\n",
      "|           |- seq\n",
      "|              |- hidden_states  shape=(64,)\n",
      "|- loss\n",
      "----\n",
      "[*] Starting Training Epoch 1...\n",
      "/usr/local/lib/python3.12/dist-packages/jax/_src/lax/lax.py:5518: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "[*] Training Loss: 3.5319457054138184\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/no-time-to-backprop/run_toy_task.py\", line 953, in <module>\n",
      "    (_, _, _, _, grads_for_cossim), _ = unrolled_episode_for_fbptt_grads(state_for_fbptt_grads)\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python run_toy_task.py -a ZUC -m ONLINE --num_epochs 5000 --num_steps 1000 --num_nodes 100 --num_layers 2 --num_hidden 32 --memory 2 --activation full_glu --prenorm --batch_size 50 --encoder --layer_output --extra_skip --decoder MLP --mixing rotational_full --acc --dont_store_results --steps_for_scheduler 20 --lr_schedule cosine --rec_lr_schedule cosine --use_plateau --plateau_factor 0.2 --plateau_patience 20 --lr_min 1e-6 --rec_learning_rate 0.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
